{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f7926c-e8f7-41f0-98a4-1211da546adc",
   "metadata": {},
   "source": [
    "# Data preprocesing, Part 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c08f5-07b8-4f01-b584-d0c6d2bdc86e",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594c2c7f-3fff-4cba-86e7-8f3031ea21d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import glob\n",
    "import pathlib\n",
    "import gcsfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cb0b4-9e25-4965-8313-42707160e4fd",
   "metadata": {},
   "source": [
    "Enter the name of the Cloud Storage bucket you used in `start_here.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc13697-f9f2-4931-8fee-85148c600d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = \"<Put the name of the bucket here>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de1e65-8e82-4339-baa6-696abd247f22",
   "metadata": {},
   "source": [
    "## Filter by store and product department and create data segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe723f6-7c62-4de5-99c6-c3a31253be61",
   "metadata": {},
   "source": [
    "After combining all columns produced in the previous notebooks, we filter the rows in the data set by `store_id` and `dept_id` and create a segment. Each segment is saved as a pickle file and then upload to Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc332147-56fb-4f11-95f1-12102aa6f1cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_data_dir = \"./processed_data/\"\n",
    "segmented_data_dir = \"./segmented_data/\"\n",
    "pathlib.Path(segmented_data_dir).mkdir(exist_ok=True)\n",
    "\n",
    "STORES = [\"CA_1\", \"CA_2\", \"CA_3\", \"CA_4\", \"TX_1\", \"TX_2\", \"TX_3\", \"WI_1\", \"WI_2\", \"WI_3\"]\n",
    "DEPTS = [\"HOBBIES_1\", \"HOBBIES_2\", \"HOUSEHOLD_1\", \"HOUSEHOLD_2\", \"FOODS_1\", \"FOODS_2\", \"FOODS_3\"]\n",
    "\n",
    "grid2_colnm = [\"sell_price\", \"price_max\", \"price_min\", \"price_std\",\n",
    "               \"price_mean\", \"price_norm\", \"price_nunique\", \"item_nunique\",\n",
    "               \"price_momentum\", \"price_momentum_m\", \"price_momentum_y\"]\n",
    "\n",
    "grid3_colnm = [\"event_name_1\", \"event_type_1\", \"event_name_2\",\n",
    "               \"event_type_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\", \"tm_d\", \"tm_w\", \"tm_m\",\n",
    "               \"tm_y\", \"tm_wm\", \"tm_dw\", \"tm_w_end\"]\n",
    "\n",
    "lag_colnm = [\"sales_lag_28\", \"sales_lag_29\", \"sales_lag_30\",\n",
    "             \"sales_lag_31\", \"sales_lag_32\", \"sales_lag_33\", \"sales_lag_34\",\n",
    "             \"sales_lag_35\", \"sales_lag_36\", \"sales_lag_37\", \"sales_lag_38\",\n",
    "             \"sales_lag_39\", \"sales_lag_40\", \"sales_lag_41\", \"sales_lag_42\",\n",
    "             \"rolling_mean_7\", \"rolling_std_7\", \"rolling_mean_14\", \"rolling_std_14\",\n",
    "             \"rolling_mean_30\", \"rolling_std_30\", \"rolling_mean_60\",\n",
    "             \"rolling_std_60\", \"rolling_mean_180\", \"rolling_std_180\"]\n",
    "\n",
    "target_enc_colnm = [\n",
    "    \"enc_store_id_dept_id_mean\", \"enc_store_id_dept_id_std\",\n",
    "    \"enc_item_id_state_id_mean\", \"enc_item_id_state_id_std\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36fbfd16-83e6-42ab-a337-5dd9a009cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(store, dept=None):\n",
    "    \"\"\"\n",
    "    Filter and clean data according to stores and product departments\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    store: Filter data by retaining rows whose store_id matches this parameter.\n",
    "    dept: Filter data by retaining rows whose dept_id matches this parameter.\n",
    "          This parameter can be set to None to indicate that we shouldn't filter by dept_id.\n",
    "    \"\"\"\n",
    "    if store is None:\n",
    "        raise ValueError(f\"store parameter must not be None\")\n",
    "\n",
    "    grid1 = cudf.DataFrame(pd.read_pickle(processed_data_dir + \"grid_df_part1.pkl\"))\n",
    "\n",
    "    if dept is None:\n",
    "        grid1 = grid1[grid1[\"store_id\"] == store]\n",
    "    else:\n",
    "        grid1 = grid1[(grid1[\"store_id\"] == store) & (grid1[\"dept_id\"] == dept)].drop(columns=[\"dept_id\"])\n",
    "    grid1 = grid1.drop(columns=[\"release_week\", \"wm_yr_wk\", \"store_id\", \"state_id\"])\n",
    "\n",
    "    grid2 = cudf.DataFrame(pd.read_pickle(processed_data_dir + \"grid_df_part2.pkl\"))[[\"id\", \"day_id\"] + grid2_colnm]\n",
    "    grid_df = grid1.merge(grid2, on=[\"id\", \"day_id\"], how=\"left\")\n",
    "    del grid1, grid2\n",
    "\n",
    "    grid3 = cudf.DataFrame(pd.read_pickle(processed_data_dir + \"grid_df_part3.pkl\"))[[\"id\", \"day_id\"] + grid3_colnm]\n",
    "    grid_df = grid_df.merge(grid3, on=[\"id\", \"day_id\"], how=\"left\")\n",
    "    del grid3\n",
    "\n",
    "    lag_df = cudf.DataFrame(pd.read_pickle(processed_data_dir + \"lags_df_28.pkl\"))[[\"id\", \"day_id\"] + lag_colnm]\n",
    "\n",
    "    grid_df = grid_df.merge(lag_df, on=[\"id\", \"day_id\"], how=\"left\")\n",
    "    del lag_df\n",
    "\n",
    "    target_enc_df = cudf.DataFrame(pd.read_pickle(processed_data_dir + \"target_encoding_df.pkl\"))[[\"id\", \"day_id\"] + target_enc_colnm]\n",
    "\n",
    "    grid_df = grid_df.merge(target_enc_df, on=[\"id\", \"day_id\"], how=\"left\")\n",
    "    del target_enc_df\n",
    "    gc.collect()\n",
    "\n",
    "    grid_df = grid_df.drop(columns=[\"id\"])\n",
    "    grid_df[\"day_id\"] = grid_df[\"day_id\"].to_pandas().astype(\"str\").apply(lambda x: x[2:]).astype(np.int16)\n",
    "\n",
    "    return grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e61b762-2722-4b83-9220-326006880acd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store CA_1...\n",
      "Processing store CA_2...\n",
      "Processing store CA_3...\n",
      "Processing store CA_4...\n",
      "Processing store TX_1...\n",
      "Processing store TX_2...\n",
      "Processing store TX_3...\n",
      "Processing store WI_1...\n",
      "Processing store WI_2...\n",
      "Processing store WI_3...\n",
      "Processing (store CA_1, department HOBBIES_1)...\n",
      "Processing (store CA_1, department HOBBIES_2)...\n",
      "Processing (store CA_1, department HOUSEHOLD_1)...\n",
      "Processing (store CA_1, department HOUSEHOLD_2)...\n",
      "Processing (store CA_1, department FOODS_1)...\n",
      "Processing (store CA_1, department FOODS_2)...\n",
      "Processing (store CA_1, department FOODS_3)...\n",
      "Processing (store CA_2, department HOBBIES_1)...\n",
      "Processing (store CA_2, department HOBBIES_2)...\n",
      "Processing (store CA_2, department HOUSEHOLD_1)...\n",
      "Processing (store CA_2, department HOUSEHOLD_2)...\n",
      "Processing (store CA_2, department FOODS_1)...\n",
      "Processing (store CA_2, department FOODS_2)...\n",
      "Processing (store CA_2, department FOODS_3)...\n",
      "Processing (store CA_3, department HOBBIES_1)...\n",
      "Processing (store CA_3, department HOBBIES_2)...\n",
      "Processing (store CA_3, department HOUSEHOLD_1)...\n",
      "Processing (store CA_3, department HOUSEHOLD_2)...\n",
      "Processing (store CA_3, department FOODS_1)...\n",
      "Processing (store CA_3, department FOODS_2)...\n",
      "Processing (store CA_3, department FOODS_3)...\n",
      "Processing (store CA_4, department HOBBIES_1)...\n",
      "Processing (store CA_4, department HOBBIES_2)...\n",
      "Processing (store CA_4, department HOUSEHOLD_1)...\n",
      "Processing (store CA_4, department HOUSEHOLD_2)...\n",
      "Processing (store CA_4, department FOODS_1)...\n",
      "Processing (store CA_4, department FOODS_2)...\n",
      "Processing (store CA_4, department FOODS_3)...\n",
      "Processing (store TX_1, department HOBBIES_1)...\n",
      "Processing (store TX_1, department HOBBIES_2)...\n",
      "Processing (store TX_1, department HOUSEHOLD_1)...\n",
      "Processing (store TX_1, department HOUSEHOLD_2)...\n",
      "Processing (store TX_1, department FOODS_1)...\n",
      "Processing (store TX_1, department FOODS_2)...\n",
      "Processing (store TX_1, department FOODS_3)...\n",
      "Processing (store TX_2, department HOBBIES_1)...\n",
      "Processing (store TX_2, department HOBBIES_2)...\n",
      "Processing (store TX_2, department HOUSEHOLD_1)...\n",
      "Processing (store TX_2, department HOUSEHOLD_2)...\n",
      "Processing (store TX_2, department FOODS_1)...\n",
      "Processing (store TX_2, department FOODS_2)...\n",
      "Processing (store TX_2, department FOODS_3)...\n",
      "Processing (store TX_3, department HOBBIES_1)...\n",
      "Processing (store TX_3, department HOBBIES_2)...\n",
      "Processing (store TX_3, department HOUSEHOLD_1)...\n",
      "Processing (store TX_3, department HOUSEHOLD_2)...\n",
      "Processing (store TX_3, department FOODS_1)...\n",
      "Processing (store TX_3, department FOODS_2)...\n",
      "Processing (store TX_3, department FOODS_3)...\n",
      "Processing (store WI_1, department HOBBIES_1)...\n",
      "Processing (store WI_1, department HOBBIES_2)...\n",
      "Processing (store WI_1, department HOUSEHOLD_1)...\n",
      "Processing (store WI_1, department HOUSEHOLD_2)...\n",
      "Processing (store WI_1, department FOODS_1)...\n",
      "Processing (store WI_1, department FOODS_2)...\n",
      "Processing (store WI_1, department FOODS_3)...\n",
      "Processing (store WI_2, department HOBBIES_1)...\n",
      "Processing (store WI_2, department HOBBIES_2)...\n",
      "Processing (store WI_2, department HOUSEHOLD_1)...\n",
      "Processing (store WI_2, department HOUSEHOLD_2)...\n",
      "Processing (store WI_2, department FOODS_1)...\n",
      "Processing (store WI_2, department FOODS_2)...\n",
      "Processing (store WI_2, department FOODS_3)...\n",
      "Processing (store WI_3, department HOBBIES_1)...\n",
      "Processing (store WI_3, department HOBBIES_2)...\n",
      "Processing (store WI_3, department HOUSEHOLD_1)...\n",
      "Processing (store WI_3, department HOUSEHOLD_2)...\n",
      "Processing (store WI_3, department FOODS_1)...\n",
      "Processing (store WI_3, department FOODS_2)...\n",
      "Processing (store WI_3, department FOODS_3)...\n"
     ]
    }
   ],
   "source": [
    "# First save the segment to the disk\n",
    "for store in STORES:\n",
    "    print(f\"Processing store {store}...\")\n",
    "    grid_df = prepare_data(store=store)\n",
    "    grid_df.to_pandas().to_pickle(segmented_data_dir + f\"combined_df_store_{store}.pkl\")\n",
    "    del grid_df\n",
    "    gc.collect()\n",
    "\n",
    "for store in STORES:\n",
    "    for dept in DEPTS:\n",
    "        print(f\"Processing (store {store}, department {dept})...\")\n",
    "        grid_df = prepare_data(store=store, dept=dept)\n",
    "        grid_df.to_pandas().to_pickle(segmented_data_dir + f\"combined_df_store_{store}_dept_{dept}.pkl\")\n",
    "        del grid_df\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e12341b-c879-4012-8c73-8316278b9a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./segmented_data/combined_df_store_WI_1_dept_FOODS_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_2_dept_FOODS_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_2_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_2_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_1_dept_FOODS_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_1_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_3_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_3_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_2_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_4_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_3_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_1_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_1_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_4_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_1_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_3_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_3_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_1_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_1_dept_FOODS_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_4.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_1_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_2_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_3_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_1_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_1_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_2_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_2_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_3_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_3_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_2_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_2_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_3_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_4_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_4_dept_FOODS_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_3_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_1_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_3_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_4_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_1_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_3_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_3_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_2_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_2_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_1_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_1_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_3_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_1_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_2_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_4_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_1_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_2_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_2_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_1_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_3_dept_FOODS_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_2_dept_FOODS_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_2_dept_FOODS_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_2_dept_HOUSEHOLD_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_2_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_2_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_1_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_3_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_3_dept_FOODS_3.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_4_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_CA_3_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_3_dept_HOUSEHOLD_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_2_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_1_dept_FOODS_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_2_dept_FOODS_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_TX_3_dept_HOBBIES_2.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_1_dept_HOBBIES_1.pkl...\n",
      "Uploading ./segmented_data/combined_df_store_WI_3_dept_FOODS_3.pkl...\n"
     ]
    }
   ],
   "source": [
    "# Then copy the segment to Cloud Storage\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "for e in glob.glob(segmented_data_dir + \"*\"):\n",
    "    print(f\"Uploading {e}...\")\n",
    "    basename = pathlib.Path(e).name\n",
    "    fs.put_file(e, f\"{bucket_name}/{basename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58eb85e7-3d1d-4f72-8c9a-57b672344d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Also upload the product weights\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "fs.put_file(processed_data_dir + \"product_weights.pkl\", f\"{bucket_name}/product_weights.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf03ee-3e08-429d-bff0-8023ee6de2af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
