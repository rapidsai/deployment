{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "workflows/hpo",
     "cloud/azure/ml",
     "library/cudf",
     "library/cuml",
     "library/randomforest"
    ]
   },
   "source": [
    "# Train and Hyperparameter-Tune with RAPIDS on AzureML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing an optimal set of hyperparameters is a daunting task, especially for algorithms like XGBoost that have many hyperparameters to tune. \n",
    "\n",
    "In this notebook, we will show how to speed up hyperparameter optimization by running multiple training jobs in parallel on [Azure Machine Learning (AzureML)](https://azure.microsoft.com/en-us/products/machine-learning) service.\n",
    "# Prerequisites\n",
    "\n",
    "````{docref} /cloud/azure/azureml\n",
    "Create an Azure ML [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) then follow instructions in [Microsoft Azure Machine Learning](../../cloud/azure/azureml) to launch an Azure ML Compute instance with RAPIDS.\n",
    "\n",
    "Once your instance is running and you have access to Jupyter save this notebook and run through the cells.\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azure-ai-ml\n",
      "Version: 1.8.0\n",
      "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
      "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
      "Author: Microsoft Corporation\n",
      "Author-email: azuresdkengsysadmins@microsoft.com\n",
      "License: MIT License\n",
      "Location: /anaconda/envs/rapids/lib/python3.10/site-packages\n",
      "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# verify Azure ML SDK version\n",
    "\n",
    "%pip show azure-ai-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize `MLClient` [class](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.mlclient?view=azure-python) to handle the workspace you created in the prerequisites step. \n",
    "\n",
    "You can manually provide the workspace details or call `MLClient.from_config(credential, path)`\n",
    "to create a workspace object from the details stored in `config.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: rapids-aml-cluster\n",
      "Subscription id: fc4f4a6b-4041-4b1c-8249-854d68edcf62\n",
      "Resource group: rapidsai-deployment\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "subscription_id = \"FILL IN WITH YOUR AZURE ML CREDENTIALS\"\n",
    "resource_group_name = \"FILL IN WITH YOUR AZURE ML CREDENTIALS\"\n",
    "workspace_name = \"FILL IN WITH YOUR AZURE ML CREDENTIALS\"\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group_name,\n",
    "    workspace_name=workspace_name,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Workspace name: \" + ml_client.workspace_name,\n",
    "    \"Subscription id: \" + ml_client.subscription_id,\n",
    "    \"Resource group: \" + ml_client.resource_group_name,\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Access Data from Datastore URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use 20 million rows of the airline dataset. The [datastore uri](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-access-data-interactive?tabs=adls#access-data-from-a-datastore-uri-like-a-filesystem-preview) below references a data storage location (path) containing the parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data uri: \n",
      " azureml://subscriptions/fc4f4a6b-4041-4b1c-8249-854d68edcf62/resourcegroups/rapidsai-deployment/workspaces/rapids-aml-cluster/datastores/workspaceartifactstore/paths/airline_20000000.parquet\n"
     ]
    }
   ],
   "source": [
    "datastore_name = \"workspaceartifactstore\"\n",
    "dataset = \"airline_20000000.parquet\"\n",
    "\n",
    "# Datastore uri format:\n",
    "data_uri = f\"azureml://subscriptions/{ml_client.subscription_id}/resourcegroups/{ml_client.resource_group_name}/workspaces/{ml_client.workspace_name}/datastores/{datastore_name}/paths/{dataset}\"\n",
    "\n",
    "print(\"data uri:\", \"\\n\", data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create AML Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to create an Azure ML managed compute target ([AmlCompute](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster?view=azureml-api-2&tabs=python)) to serve as the environment for training your model.\n",
    "\n",
    "This notebook will use 10 nodes for hyperparameter optimization, you can modify `max_instances` based on available quota in the desired region. Similar to other Azure ML services, there are limits on AmlCompute, this [article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) includes details on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`size` describes the virtual machine type and size that will be used in the cluster. See \"System Requirements\" in the RAPIDS docs ([link](https://docs.rapids.ai/install#system-req)) and \"GPU optimized virtual machine sizes\" in the Azure docs ([link](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu)) to identify an instance type.\n",
    "\n",
    "Let's create an `AmlCompute` cluster of `Standard_NC12s_v3` (Tesla V100) GPU VMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. Will use rapids-cluster\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.ai.ml.exceptions import MlException\n",
    "\n",
    "# specify aml compute name.\n",
    "gpu_compute_target = \"rapids-cluster\"\n",
    "\n",
    "try:\n",
    "    # let's see if the compute target already exists\n",
    "    gpu_target = ml_client.compute.get(gpu_compute_target)\n",
    "    print(f\"found compute target. Will use {gpu_compute_target}\")\n",
    "except MlException:\n",
    "    print(\"Creating a new gpu compute target...\")\n",
    "\n",
    "    gpu_target = AmlCompute(\n",
    "        name=\"rapids-cluster\",\n",
    "        type=\"amlcompute\",\n",
    "        size=\"STANDARD_NC12S_V3\",\n",
    "        max_instances=5,\n",
    "        idle_time_before_scale_down=300,\n",
    "    )\n",
    "    ml_client.compute.begin_create_or_update(gpu_target).result()\n",
    "\n",
    "    print(\n",
    "        f\"AMLCompute with name {gpu_target.name} is created, the compute size is {gpu_target.size}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Prepare training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "library/cuml"
    ]
   },
   "source": [
    "Make sure current directory contains your code to run on the remote resource. This includes the training script and all its dependencies files. In this example, the training script is provided:\n",
    "\n",
    "`train_rapids.py`- entry script for RAPIDS Environment, includes loading dataset into cuDF dataframe, training with Random Forest and inference using cuML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will log some parameters and metrics including highest accuracy, using mlflow within the training script:\n",
    "\n",
    "```console\n",
    "import mlflow\n",
    "\n",
    "mlflow.log_metric('Accuracy', np.float(global_best_test_accuracy))\n",
    "```\n",
    "\n",
    "These run metrics will become particularly important when we begin hyperparameter tuning our model in the 'Tune model hyperparameters' section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapids_script = \"./train_rapids.py\"\n",
    "azure_script = \"./rapids_csp_azure.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Model on Remote Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment\n",
    "\n",
    "Track all the runs in your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"test_rapids_aml_cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a custom RAPIDS docker image to [setup the environment](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-environments-v2?tabs=python#create-an-environment-from-a-docker-image). This is available in `rapidsai/rapidsai` repo on [DockerHub](https://hub.docker.com/r/rapidsai/rapidsai/).\n",
    "\n",
    "Make sure you have the correct path to the docker build context as `os.getcwd()`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading code (0.33 MBs): 100%|██████████| 325450/325450 [00:00<00:00, 2363322.62it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Environment({'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'rapids-mlflow', 'description': 'RAPIDS environment with azureml-mlflow', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/fc4f4a6b-4041-4b1c-8249-854d68edcf62/resourceGroups/rapidsai-deployment/providers/Microsoft.MachineLearningServices/workspaces/rapids-aml-cluster/environments/rapids-mlflow/versions/10', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/skirui1/code', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f9ce47101f0>, 'serialize': <msrest.serialization.Serializer object at 0x7f9ce4710d30>, 'version': '10', 'latest_version': None, 'conda_file': None, 'image': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x7f9ce4713580>, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CODE ONCE TO SETUP ENVIRONMENT\n",
    "import os\n",
    "\n",
    "from azure.ai.ml.entities import BuildContext, Environment\n",
    "\n",
    "env_docker_image = Environment(\n",
    "    build=BuildContext(path=os.getcwd()),\n",
    "    name=\"rapids-mlflow\",\n",
    "    description=\"RAPIDS environment with azureml-mlflow\",\n",
    ")\n",
    "\n",
    "ml_client.environments.create_or_update(env_docker_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the Training Job "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will configure and run a training job using the`command`class. The [command](https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml?view=azure-python#azure-ai-ml-command) can be used to run standalone jobs or as a function inside pipelines.\n",
    "`inputs` is a dictionary of command-line arguments to pass to the training script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "library/randomforest",
     "library/cudf"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading code (0.33 MBs): 100%|██████████| 327210/327210 [00:00<00:00, 1802654.05it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://ml.azure.com/runs/zen_eye_lm7dcp68jz?wsid=/subscriptions/fc4f4a6b-4041-4b1c-8249-854d68edcf62/resourcegroups/rapidsai-deployment/workspaces/rapids-aml-cluster&tid=43083d15-7273-40c1-b7db-39efd9ccc17a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import Input, command\n",
    "\n",
    "command_job = command(\n",
    "    environment=\"rapids-mlflow:1\",\n",
    "    experiment_name=experiment_name,\n",
    "    code=os.getcwd(),\n",
    "    inputs={\n",
    "        \"data_dir\": Input(type=\"uri_file\", path=data_uri),\n",
    "        \"n_bins\": 32,\n",
    "        \"compute\": \"single-GPU\",  # multi-GPU for algorithms via Dask\n",
    "        \"cv_folds\": 5,\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 6,\n",
    "        \"max_features\": 0.3,\n",
    "    },\n",
    "    command=(\n",
    "        \"python train_rapids.py --data_dir ${{inputs.data_dir}} --n_bins ${{inputs.n_bins}} \"\n",
    "        \"--compute ${{inputs.compute}} --cv_folds ${{inputs.cv_folds}} --n_estimators ${{inputs.n_estimators}} \"\n",
    "        \"--max_depth ${{inputs.max_depth}}  --max_features ${{inputs.max_features}}\"\n",
    "    ),\n",
    "    compute=\"rapids-cluster\",\n",
    ")\n",
    "\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "\n",
    "# get a URL for the status of the job\n",
    "returned_job.studio_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune Model Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can optimize our model's hyperparameters and improve the accuracy using Azure Machine Learning's hyperparameter tuning capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a Hyperparameter Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the hyperparameter space to sweep over. We will tune `n_estimators`, `max_depth` and `max_features` parameters. In this example we will use random sampling to try different configuration sets of hyperparameters and maximize `Accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Uniform\n",
    "\n",
    "command_job_for_sweep = command_job(\n",
    "    n_estimators=Choice(values=range(50, 500)),\n",
    "    max_depth=Choice(values=range(5, 19)),\n",
    "    max_features=Uniform(min_value=0.2, max_value=1.0),\n",
    ")\n",
    "\n",
    "# apply sweep parameter to obtain the sweep_job\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"rapids-cluster\",\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"Accuracy\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "\n",
    "\n",
    "# Define the limits for this sweep\n",
    "sweep_job.set_limits(\n",
    "    max_total_trials=10, max_concurrent_trials=2, timeout=18000, trial_timeout=3600\n",
    ")\n",
    "\n",
    "\n",
    "# Specify your experiment details\n",
    "sweep_job.display_name = \"RF-rapids-sweep-job\"\n",
    "sweep_job.description = \"Run RAPIDS hyperparameter sweep job\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will launch the RAPIDS training script with parameters that were specified in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the hpo job\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor SweepJobs runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/eager_turtle_r7fs2xzcty?wsid=/subscriptions/fc4f4a6b-4041-4b1c-8249-854d68edcf62/resourcegroups/rapidsai-deployment/workspaces/rapids-aml-cluster&tid=43083d15-7273-40c1-b7db-39efd9ccc17a\n"
     ]
    }
   ],
   "source": [
    "aml_url = returned_sweep_job.studio_url\n",
    "\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Register Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the best trial model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.download(returned_sweep_job.name, output_name=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.compute.begin_delete(gpu_compute_target).wait()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "rapids"
  },
  "kernelspec": {
   "display_name": "rapids-23.06",
   "language": "python",
   "name": "rapids-23.06"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
