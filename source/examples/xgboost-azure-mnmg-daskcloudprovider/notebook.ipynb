{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# <span style=\"color:#8735fb; font-size:24pt\"> Multi-Node Multi-GPU XGBoost example on Azure using dask-cloudprovider </span>\n",
    "\n",
    "[Dask Cloud Provider](https://cloudprovider.dask.org/en/latest/) is a native cloud intergration library for Dask. It helps manage Dask clusters on different cloud platforms. In this notebook, we will look at how we can use this package to set-up an Azure cluster and run a multi-node multi-GPU (MNMG) example with [RAPIDS](https://rapids.ai/). RAPIDS provides a suite of libraries to accelerate data science pipelines on the GPU entirely. This can be scaled to multiple nodes using Dask as we will see in this notebook. \n",
    "\n",
    "For the purposes of this demo, we will use a part of the NYC Taxi Dataset (only the files of 2014 calendar year will be used here). The goal is to predict the fare amount for a given trip given the times and coordinates of the taxi trip. We will download the data from [Azure Open Datasets](https://docs.microsoft.com/en-us/azure/open-datasets/overview-what-are-open-datasets), where the dataset is publicly hosted by Microsoft.\n",
    "\n",
    "---\n",
    "\n",
    "**NOTE:**  In this notebook, we will explore two possible ways to use `dask-cloudprovider` to run our workloads on Azure VM clusters:\n",
    "\n",
    "1. [Option 1](#-Option-1:-Use-an-Azure-marketplace-VM.-): Using an [Azure Marketplace image](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/nvidia.ngc_azure_17_11?tab=overview) made available for free from NVIDIA. The RAPIDS container will be subsequently downloaded once the VMs start up.\n",
    "2. [Option 2](#-Option-2:-Set-up-an-Azure-Customized-VM.-): Using [`packer`](https://docs.microsoft.com/en-us/azure/virtual-machines/linux/build-image-with-packer) to create a custom VM image to be used in the cluster. This image will include the RAPIDS container, and having the container already inside the image should speed up the process of provisioning the cluster.\n",
    "\n",
    "#### You can either use Option 1 or use Option 2.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "library/xgboost"
    ]
   },
   "source": [
    "## <span style=\"color:#8735fb; font-size:22pt\"> Step 0: Set up Azure credentials and CLI </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the notebook, run the following commands in the terminal to setup Azure CLI\n",
    "```\n",
    "curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n",
    "az login\n",
    "```\n",
    "Then, follow the instructions on the prompt to finish setting up the account. If you are running the notebook from inside a Docker container, you can remove `sudo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mA web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\u001b[0m\n",
      "[\n",
      "  {\n",
      "    \"cloudName\": \"AzureCloud\",\n",
      "    \"homeTenantId\": \"43083d15-7273-40c1-b7db-39efd9ccc17a\",\n",
      "    \"id\": \"fc4f4a6b-4041-4b1c-8249-854d68edcf62\",\n",
      "    \"isDefault\": true,\n",
      "    \"managedByTenants\": [\n",
      "      {\n",
      "        \"tenantId\": \"2f4a9838-26b7-47ee-be60-ccc1fdec5953\"\n",
      "      }\n",
      "    ],\n",
      "    \"name\": \"NV-AI-Infra\",\n",
      "    \"state\": \"Enabled\",\n",
      "    \"tenantId\": \"43083d15-7273-40c1-b7db-39efd9ccc17a\",\n",
      "    \"user\": {\n",
      "      \"name\": \"skirui@nvidia.com\",\n",
      "      \"type\": \"user\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:#8735fb; font-size:22pt\"> Step 1: Import necessary packages </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adlfs in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (2023.8.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from adlfs) (1.29.3)\n",
      "Requirement already satisfied: azure-datalake-store<0.1,>=0.0.46 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from adlfs) (0.0.53)\n",
      "Requirement already satisfied: azure-identity in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from adlfs) (1.14.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.12.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from adlfs) (12.17.0)\n",
      "Requirement already satisfied: fsspec>=2021.10.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from adlfs) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp>=3.7.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from adlfs) (3.8.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (1.3.1)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.1->adlfs) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.1->adlfs) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.1->adlfs) (4.7.1)\n",
      "Requirement already satisfied: cffi in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-datalake-store<0.1,>=0.0.46->adlfs) (1.15.1)\n",
      "Requirement already satisfied: msal<2,>=1.16.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-datalake-store<0.1,>=0.0.46->adlfs) (1.23.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-storage-blob>=12.12.0->adlfs) (41.0.3)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-storage-blob>=12.12.0->adlfs) (0.6.1)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-identity->adlfs) (1.0.0)\n",
      "Requirement already satisfied: pycparser in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from cffi->azure-datalake-store<0.1,>=0.0.46->adlfs) (2.21)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.46->adlfs) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity->adlfs) (2.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.1->adlfs) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.1->adlfs) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.1->adlfs) (2023.7.22)\n",
      "Requirement already satisfied: dask-cloudprovider[azure] in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (2022.10.0)\n",
      "Requirement already satisfied: aiohttp>=3.7.3 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask-cloudprovider[azure]) (3.8.5)\n",
      "Requirement already satisfied: dask>=2021.01.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask-cloudprovider[azure]) (2023.7.1)\n",
      "Requirement already satisfied: distributed>=2021.01.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask-cloudprovider[azure]) (2023.7.1)\n",
      "Requirement already satisfied: jinja2 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask-cloudprovider[azure]) (3.1.2)\n",
      "Requirement already satisfied: tornado>=5 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask-cloudprovider[azure]) (6.3.3)\n",
      "Requirement already satisfied: azure-mgmt-compute>=18.0.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask-cloudprovider[azure]) (30.1.0)\n",
      "Requirement already satisfied: azure-mgmt-network>=16.0.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask-cloudprovider[azure]) (25.0.0)\n",
      "Requirement already satisfied: azure-identity in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask-cloudprovider[azure]) (1.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.3->dask-cloudprovider[azure]) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.3->dask-cloudprovider[azure]) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.3->dask-cloudprovider[azure]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.3->dask-cloudprovider[azure]) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.3->dask-cloudprovider[azure]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.3->dask-cloudprovider[azure]) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from aiohttp>=3.7.3->dask-cloudprovider[azure]) (1.3.1)\n",
      "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-mgmt-compute>=18.0.0->dask-cloudprovider[azure]) (0.6.1)\n",
      "Requirement already satisfied: azure-common~=1.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-mgmt-compute>=18.0.0->dask-cloudprovider[azure]) (1.1.28)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.2 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-mgmt-compute>=18.0.0->dask-cloudprovider[azure]) (1.4.0)\n",
      "Requirement already satisfied: click>=8.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask>=2021.01.1->dask-cloudprovider[azure]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask>=2021.01.1->dask-cloudprovider[azure]) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask>=2021.01.1->dask-cloudprovider[azure]) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask>=2021.01.1->dask-cloudprovider[azure]) (23.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask>=2021.01.1->dask-cloudprovider[azure]) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask>=2021.01.1->dask-cloudprovider[azure]) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask>=2021.01.1->dask-cloudprovider[azure]) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from dask>=2021.01.1->dask-cloudprovider[azure]) (6.8.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from distributed>=2021.01.1->dask-cloudprovider[azure]) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from distributed>=2021.01.1->dask-cloudprovider[azure]) (1.0.5)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from distributed>=2021.01.1->dask-cloudprovider[azure]) (5.9.5)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from distributed>=2021.01.1->dask-cloudprovider[azure]) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from distributed>=2021.01.1->dask-cloudprovider[azure]) (1.7.0)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from distributed>=2021.01.1->dask-cloudprovider[azure]) (1.26.15)\n",
      "Requirement already satisfied: zict>=2.2.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from distributed>=2021.01.1->dask-cloudprovider[azure]) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from jinja2->dask-cloudprovider[azure]) (2.1.3)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.11.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-identity->dask-cloudprovider[azure]) (1.29.3)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-identity->dask-cloudprovider[azure]) (41.0.3)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.20.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-identity->dask-cloudprovider[azure]) (1.23.0)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-identity->dask-cloudprovider[azure]) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity->dask-cloudprovider[azure]) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity->dask-cloudprovider[azure]) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.11.0->azure-identity->dask-cloudprovider[azure]) (4.7.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity->dask-cloudprovider[azure]) (1.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask>=2021.01.1->dask-cloudprovider[azure]) (3.16.2)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from msal<2.0.0,>=1.20.0->azure-identity->dask-cloudprovider[azure]) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity->dask-cloudprovider[azure]) (2.7.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.7.3->dask-cloudprovider[azure]) (3.4)\n",
      "Requirement already satisfied: pycparser in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity->dask-cloudprovider[azure]) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.11.0->azure-identity->dask-cloudprovider[azure]) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "# # Uncomment the following and install some libraries at the beginning.\n",
    "# If adlfs is not present, install adlfs to read from Azure data lake.\n",
    "! pip install adlfs\n",
    "! pip install \"dask-cloudprovider[azure]\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait, get_worker\n",
    "from dask_cloudprovider.azure import AzureVMCluster\n",
    "import dask_cudf\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from cuml.dask.common import utils as dask_utils\n",
    "from cuml.metrics import mean_squared_error\n",
    "from cuml import ForestInference\n",
    "import cudf\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import dask\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#8735fb; font-size:22pt\"> Step 2: Set up the Azure VM Cluster</span>\n",
    "\n",
    "We will now set up a Dask cluster on Azure Virtual machines using `AzureVMCluster` from Dask Cloud Provider following these [instructions](https://docs.rapids.ai/deployment/stable/cloud/azure/azure-vm-multi/).\n",
    "\n",
    "To do this, you will first need to set up a Resource Group, a Virtual Network and a Security Group on Azure. [Learn more about how you can set this up](https://cloudprovider.dask.org/en/latest/azure.html#resource-groups). Note that you can also set it up using the Azure portal.\n",
    "\n",
    "Once you have set it up, you can now plug in the names of the entities you have created in the cell below. \n",
    "\n",
    "We need to pass in the docker argument `docker_args = '--shm-size=256m'` to allow larger shared memory for successfully running multiple docker containers in the same VM. This is the case when each VM has more than one worker. Even if you don't have such a case, there is no harm in having a larger shared memory. Finally, note that we use the RAPIDS docker image to build the VM and use the `dask_cuda.CUDAWorker` to run within the VM. This will run the worker docker image with GPU capabilities instead of CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"West US 2\"\n",
    "resource_group = \"rapidsai-deployment\"\n",
    "vnet = \"rapidsai-deployment-vnet\"\n",
    "security_group = \"rapidsaiclouddeploymenttest-nsg\"\n",
    "vm_size = \"Standard_NC12s_v3\"  # or choose a different GPU enabled VM type\n",
    "\n",
    "docker_image = (\n",
    "    # \"nvcr.io/nvidia/rapidsai/rapidsai-core:23.06-cuda11.8-runtime-ubuntu22.04-py3.10\"\n",
    "    \"rapidsai/base:23.08-cuda12.0-py3.10\"\n",
    ")\n",
    "docker_args = \"--shm-size=256m\"\n",
    "worker_class = \"dask_cuda.CUDAWorker\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <span style=\"color:#8735fb; font-size:20pt\"> Option 1: Use an Azure Marketplace VM image </span>\n",
    "\n",
    "In this method, we can use an Azure marketplace VM provided by NVIDIA for free. These VM images contain all the necessary dependencies and NVIDIA drivers preinstalled. These images are made available by NVIDIA as an out-of-the-box solution to decrease the cluster setup time for data scientists. Fortunately for us, `dask-cloudprovider` has made it simple to pass in information of a marketplace VM, and it will use the selected VM image instead of a vanilla image. \n",
    "\n",
    "We will use the following image -->  [NVIDIA GPU-Optimized Image for AI and HPC](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/nvidia.ngc_azure_17_11?tab=overview).\n",
    "\n",
    "**NOTE**: Please make sure you have [dask-cloudprovider](https://cloudprovider.dask.org/en/latest/) version 2021.6.0 or above. Marketplace VMs in Azure is not supported in older versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Marketplace VM information and clear default dask config. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vnet': None,\n",
       " 'security_group': None,\n",
       " 'public_ingress': True,\n",
       " 'vm_size': 'Standard_DS1_v2',\n",
       " 'disk_size': 50,\n",
       " 'scheduler_vm_size': None,\n",
       " 'docker_image': 'daskdev/dask:latest',\n",
       " 'vm_image': {'publisher': 'Canonical',\n",
       "  'offer': 'UbuntuServer',\n",
       "  'sku': '18.04-LTS',\n",
       "  'version': 'latest'},\n",
       " 'bootstrap': True,\n",
       " 'auto_shutdown': True,\n",
       " 'marketplace_plan': {'publisher': 'nvidia',\n",
       "  'name': 'ngc-base-version-23_03_0',\n",
       "  'product': 'ngc_azure_17_11',\n",
       "  'version': '23.03.0'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(\n",
    "    {\n",
    "        \"logging.distributed\": \"info\",\n",
    "        \"cloudprovider.azure.azurevm.marketplace_plan\": {\n",
    "            \"publisher\": \"nvidia\",\n",
    "            \"name\": \"ngc-base-version-23_03_0\",\n",
    "            \"product\": \"ngc_azure_17_11\",\n",
    "            \"version\": \"23.03.0\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "vm_image = \"\"\n",
    "config = dask.config.get(\"cloudprovider.azure.azurevm\", {})\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If necessary, you must uncomment and accept the Azure Marketplace image terms so that the image can be used to create VMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"accepted\": true,\n",
      "  \"id\": \"/subscriptions/fc4f4a6b-4041-4b1c-8249-854d68edcf62/providers/Microsoft.MarketplaceOrdering/offerTypes/Microsoft.MarketplaceOrdering/offertypes/publishers/nvidia/offers/ngc_azure_17_11/plans/ngc-base-version-23_03_0/agreements/current\",\n",
      "  \"licenseTextLink\": \"https://mpcprodsa.blob.core.windows.net/legalterms/3E5ED_legalterms_NVIDIA%253a24NGC%253a5FAZURE%253a5F17%253a5F11%253a24NGC%253a2DBASE%253a2DVERSION%253a2D23%253a5F03%253a5F0%253a24KJVKRIWKTRQ3CIEPNL6YTG4AVORBHHPZCDQDVWX7JPPDEF6UM7R4XO76VDRHXCNTQYATKLGYYW3KA7DSIKTYXBZ3HJ2FMWYCINEY4WQ.txt\",\n",
      "  \"marketplaceTermsLink\": \"https://mpcprodsa.blob.core.windows.net/marketplaceterms/3EDEF_marketplaceterms_VIRTUALMACHINE%253a24AAK2OAIZEAWW5H4MSP5KSTVB6NDKKRTUBAU23BRFTWN4YC2MQLJUB5ZEYUOUJBVF3YK34CIVPZL2HWYASPGDUY5O2FWEGRBYOXWZE5Y.txt\",\n",
      "  \"name\": \"ngc-base-version-23_03_0\",\n",
      "  \"plan\": \"ngc-base-version-23_03_0\",\n",
      "  \"privacyPolicyLink\": \"https://www.nvidia.com/en-us/about-nvidia/privacy-policy/\",\n",
      "  \"product\": \"ngc_azure_17_11\",\n",
      "  \"publisher\": \"nvidia\",\n",
      "  \"retrieveDatetime\": \"2023-08-29T18:09:42.2592493Z\",\n",
      "  \"signature\": \"RS4B4LMK6XWI6GNY56XH34EJDIUOSPVDCSLSAPLNIQTEPUFPG37UKLMGALXEJOHX2JHPOGZQLMIZWZ74PW7X55SS43MGT7CP3RCBFRI\",\n",
      "  \"systemData\": {\n",
      "    \"createdAt\": \"2023-08-29T18:09:44.451002+00:00\",\n",
      "    \"createdBy\": \"fc4f4a6b-4041-4b1c-8249-854d68edcf62\",\n",
      "    \"createdByType\": \"ManagedIdentity\",\n",
      "    \"lastModifiedAt\": \"2023-08-29T18:09:44.451002+00:00\",\n",
      "    \"lastModifiedBy\": \"fc4f4a6b-4041-4b1c-8249-854d68edcf62\",\n",
      "    \"lastModifiedByType\": \"ManagedIdentity\"\n",
      "  },\n",
      "  \"type\": \"Microsoft.MarketplaceOrdering/offertypes\"\n",
      "}\n",
      "\u001b[32mCommand ran in 6.000 seconds (init: 0.143, invoke: 5.856)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! az vm image terms accept --urn \"nvidia:ngc_azure_17_11:ngc-base-version-23_03_0:23.03.0\" --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that you have set up the necessary configurations to use the NVIDIA VM image, directly move to [Step 2.1](#-Step-2.1:-Start-the-VM-Cluster-in-Azure-) to start the AzureVMCluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#8735fb; font-size:20pt\"> Option 2: Set up an Azure Customized VM </span>\n",
    "\n",
    "#### If you already have a customized VM and you know its resource id, jump to [Step f. of Option 2](#f.-Set-up-customized-VM-information-and-clear-default-dask-config.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, if we use a generic image to create a cluster, we would have to wait till the new VMs are provisioned fully with all dependencies. The provisioning step does several things such as set the VM up with required libraries, set up Docker, install the NVIDIA drivers and also pull and decompress the RAPIDS container etc. This usually takes around 10-15 minutes of time depending on the cloud provider. If the user wants to fire up a cluster quickly, setting up a VM from a generic image every time may not be optimal. \n",
    "\n",
    "Further, as detailed in Option 1, we can also choose to use a custom Marketplace VM from NVIDIA. However, we will still have to download and decompress the RAPIDS container. So the setup time to start the workers and the scheduler would still be around 8-10 minutes.\n",
    "\n",
    "Luckily we can improve on this. We can make our own customized VM bundled with all the necessary packages, drivers, containers and dependencies. This way, firing up the cluster using the customized VM will take minimal time. \n",
    "\n",
    "In this example, we will be using a tool called [packer](https://www.packer.io/) to create our customized virtual machine image. Packer automates the process of building and customizing VMs across all major cloud providers. \n",
    "\n",
    "##### Now, to create a customized VM image, follow steps *a.* to *f.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Install `packer`\n",
    "\n",
    "Follow the guidelines in https://learn.hashicorp.com/tutorials/packer/get-started-install-cli?in=packer/azure-get-started to download the necessary binary according to your platform and install it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Authenticate `packer` with Azure\n",
    "There are several ways to authenticate `packer` to work with Azure (details provided [here](https://learn.hashicorp.com/tutorials/packer/get-started-install-cli?in=packer/azure-get-started)). However, since we already have installed Azure cli (`az`) at the beginning of the notebook, authenticating `packer` with `az` cli is the easiest option. We will let `packer` use the Azure credentials from `az` cli, and so, you do not have to do anything further in this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### c. Generate the cloud init script for customizing the VM image\n",
    "\n",
    "`packer` can use a [cloud-init](https://cloudinit.readthedocs.io/en/latest/) script to initialize a VM. The cloud init script contains the set of commands that will set up the environment of our customized VM. We will pass this as an external file to the `packer` command via a configuration script.\n",
    "\n",
    "The cloud init file [cloud_init.yaml.j2](./configs/cloud_init.yaml.j2) file is present in the `configs` folder. In case you want to add/modify any configuration, edit the [cloud_init.yaml.j2](./configs/cloud_init.yaml.j2) before proceeding to the next steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Write packer configuration to a configuration file\n",
    "We now need to provide `packer` with a build file with platform related and cloud-init configurations. `packer` will use this to create the customized VM. \n",
    "\n",
    "In this example, we are creating a single custom VM image that will be accessible by the user only. We will use a Ubuntu Server 18.04 base image and customize it. Later on, we will instantiate all our VMs from this customized VM image.\n",
    "\n",
    "If you are curious about what else you can configure, take a look at all the available [Azure build parameters for `packer`](https://www.packer.io/docs/builders/azure/arm).\n",
    "\n",
    "**Note:** Our resource group already exists in this example. Hence we simply pass in our resource group name in the required parameters `managed_image_resource_group_name` and `build_resource_group_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packer_config = {\n",
    "  \"builders\": [{\n",
    "    \"type\": \"azure-arm\", \n",
    "    \"use_azure_cli_auth\": True,\n",
    "    \"managed_image_resource_group_name\": resource_group,\n",
    "    \"managed_image_name\": <the name of the customized VM image>,\n",
    "    \"custom_data_file\": \"./configs/cloud_init.yaml.j2\",\n",
    "    \"os_type\": \"Linux\",\n",
    "    \"image_publisher\": \"Canonical\", \n",
    "    \"image_offer\": \"UbuntuServer\",\n",
    "    \"image_sku\": \"18.04-LTS\",\n",
    "    \"azure_tags\": {\n",
    "        \"dept\": \"RAPIDS-CSP\",\n",
    "        \"task\": \"RAPIDS Custom Image deployment\"\n",
    "    },\n",
    "    \"build_resource_group_name\": resource_group,\n",
    "    \"vm_size\": vm_size\n",
    "  }],\n",
    "  \"provisioners\": [{\n",
    "    \"inline\": [\n",
    "      \"echo 'Waiting for cloud-init'; while [ ! -f /var/lib/cloud/instance/boot-finished ]; do sleep 1; done; echo 'Done'\",\n",
    "    ],\n",
    "    \"type\": \"shell\"\n",
    "  }]\n",
    "}\n",
    "\n",
    "with open(\"packer_config.json\", \"w\") as fh:\n",
    "    fh.write(json.dumps(packer_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### e. Run `packer` build and create the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the following line and run to create the custom image\n",
    "# ! packer build packer_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take around 15 minutes. Grab a coffee or watch an episode of your favourite tv show and come back. But remember, you will only have to do this once, unless you want to update the packages in the VM. This means that you can make this custom image once, and then keep on using it for hundreds of times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### While packer is building the image, you will see an output similar to what is shown below. \n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "azure-arm: output will be in this color.\n",
    "\n",
    "==> azure-arm: Running builder ...\n",
    "==> azure-arm: Getting tokens using Azure CLI\n",
    "==> azure-arm: Getting tokens using Azure CLI\n",
    "    azure-arm: Creating Azure Resource Manager (ARM) client ...\n",
    "==> azure-arm: Using existing resource group ...\n",
    "==> azure-arm:  -> ResourceGroupName : <your resource group>\n",
    "==> azure-arm:  -> Location          : <some chosen location>\n",
    "==> azure-arm: Validating deployment template ...\n",
    "==> azure-arm:  -> ResourceGroupName : <your resource group>\n",
    "==> azure-arm:  -> DeploymentName    : 'pkrdp04rrahxkg9'\n",
    "==> azure-arm: Deploying deployment template ...\n",
    "==> azure-arm:  -> ResourceGroupName : <your resource group>\n",
    "==> azure-arm:  -> DeploymentName    : 'pkrdp04rrahxkg9'\n",
    "==> azure-arm:\n",
    "==> azure-arm: Getting the VM's IP address ...\n",
    "==> azure-arm:  -> ResourceGroupName   : <your resource group>\n",
    "==> azure-arm:  -> PublicIPAddressName : 'pkrip04rrahxkg9'\n",
    "==> azure-arm:  -> NicName             : 'pkrni04rrahxkg9'\n",
    "==> azure-arm:  -> Network Connection  : 'PublicEndpoint'\n",
    "==> azure-arm:  -> IP Address          : '40.77.62.118'\n",
    "==> azure-arm: Waiting for SSH to become available...\n",
    "==> azure-arm: Connected to SSH!\n",
    "==> azure-arm: Provisioning with shell script: /tmp/packer-shell614221056\n",
    "    azure-arm: Waiting for cloud-init\n",
    "    azure-arm: Done\n",
    "==> azure-arm: Querying the machine's properties ...\n",
    "==> azure-arm:  -> ResourceGroupName : <your resource group>\n",
    "==> azure-arm:  -> ComputeName       : 'pkrvm04rrahxkg9'\n",
    "==> azure-arm:  -> Managed OS Disk   : '/subscriptions/<your subscription id>/resourceGroups/<your resource group>/providers/Microsoft.Compute/disks/pkros04rrahxkg9'\n",
    "==> azure-arm: Querying the machine's additional disks properties ...\n",
    "==> azure-arm:  -> ResourceGroupName : <your resource group>\n",
    "==> azure-arm:  -> ComputeName       : 'pkrvm04rrahxkg9'\n",
    "==> azure-arm: Powering off machine ...\n",
    "==> azure-arm:  -> ResourceGroupName : <your resource group>\n",
    "==> azure-arm:  -> ComputeName       : 'pkrvm04rrahxkg9'\n",
    "==> azure-arm: Capturing image ...\n",
    "==> azure-arm:  -> Compute ResourceGroupName : <your resource group>\n",
    "==> azure-arm:  -> Compute Name              : 'pkrvm04rrahxkg9'\n",
    "==> azure-arm:  -> Compute Location          : <some chosen location>\n",
    "==> azure-arm:  -> Image ResourceGroupName   : <your resource group>\n",
    "==> azure-arm:  -> Image Name                : <your chosen custom image name>\n",
    "==> azure-arm:  -> Image Location            : <some chosen location>\n",
    "==> azure-arm: \n",
    "==> azure-arm: Deleting individual resources ...\n",
    "==> azure-arm: Adding to deletion queue -> Microsoft.Compute/virtualMachines : 'pkrvm04rrahxkg9'\n",
    "==> azure-arm: Adding to deletion queue -> Microsoft.Network/networkInterfaces : 'pkrni04rrahxkg9'\n",
    "==> azure-arm: Adding to deletion queue -> Microsoft.Network/publicIPAddresses : 'pkrip04rrahxkg9'\n",
    "==> azure-arm: Adding to deletion queue -> Microsoft.Network/virtualNetworks : 'pkrvn04rrahxkg9'\n",
    "==> azure-arm: Attempting deletion -> Microsoft.Network/networkInterfaces : 'pkrni04rrahxkg9'\n",
    "==> azure-arm: Waiting for deletion of all resources...\n",
    "==> azure-arm: Attempting deletion -> Microsoft.Network/publicIPAddresses : 'pkrip04rrahxkg9'\n",
    "==> azure-arm: Attempting deletion -> Microsoft.Compute/virtualMachines : 'pkrvm04rrahxkg9'\n",
    "==> azure-arm: Attempting deletion -> Microsoft.Network/virtualNetworks : 'pkrvn04rrahxkg9'\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "==> azure-arm:  Deleting -> Microsoft.Compute/disks : '/subscriptions/<your subscription id>/resourceGroups/<your resource group>/providers/Microsoft.Compute/disks/pkros04rrahxkg9'\n",
    "==> azure-arm: Removing the created Deployment object: 'pkrdp04rrahxkg9'\n",
    "==> azure-arm: \n",
    "==> azure-arm: The resource group was not created by Packer, not deleting ...\n",
    "Build 'azure-arm' finished after 16 minutes 22 seconds.\n",
    "\n",
    "==> Wait completed after 16 minutes 22 seconds\n",
    "\n",
    "==> Builds finished. The artifacts of successful builds are:\n",
    "--> azure-arm: Azure.ResourceManagement.VMImage:\n",
    "\n",
    "OSType: Linux\n",
    "ManagedImageResourceGroupName: <your resource group>\n",
    "ManagedImageName: <your chosen custom image name>\n",
    "ManagedImageId: /subscriptions/<your subscription id>/resourceGroups/<your resource group>/providers/Microsoft.Compute/images/<your chosen custom image name>\n",
    "ManagedImageLocation: <some chosen location>\n",
    "\n",
    "```\n",
    "---\n",
    "    \n",
    "##### When `packer` finishes, at the bottom of the output, you will see something similar to the following:\n",
    "```\n",
    "ManagedImageResourceGroupName: <your resource group>\n",
    "ManagedImageName: <your chosen custom image name>\n",
    "ManagedImageId: /subscriptions/<your subscription id>/resourceGroups/<your resource group>/providers/Microsoft.Compute/images/<your chosen custom image name>\n",
    "ManagedImageLocation: <some chosen location>\n",
    "```\n",
    "\n",
    "##### Make note of the `ManagedImageId`. This is the resource id of the custom image we will use. \n",
    "As shown above the `ManagedImageId` will look something like : `/subscriptions/12345/resourceGroups/myown-rg/providers/Microsoft.Compute/images/myCustomImage`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### f. Set up customized VM information and clear default dask config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the custom VM resource id, you should reset the default VM image information in `dask.config`. The default image value loaded in `dask.config` is that of a basic Ubuntu Server 18.04 LTS (the one that you already customized). If you do not reset it, `dask` will try to use that image instead of your custom made one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ManagedImageId = <value from the output above> # or the customized VM id if you already have resource id of the customized VM from a previous run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set({\"cloudprovider.azure.azurevm.vm_image\": {}})\n",
    "config = dask.config.get(\"cloudprovider.azure.azurevm\", {})\n",
    "print(config)\n",
    "vm_image = {\"id\": ManagedImageId}\n",
    "print(vm_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#8735fb; font-size:20pt\"> Step 2.1: Start the VM Cluster in Azure </span>\n",
    "\n",
    "Here, if you have used Option 1, i.e., the NVIDIA VM image, pass an empty string for `vm_image` information. \n",
    "\n",
    "For Option 2, pass the `vm_image` information that you got from the output of `packer` run as a parameter to `AzureVMCluster`. \n",
    "\n",
    "Also turn off the bootstrapping of the VM by passing `bootstrap=False`. This will turn off installation of the dependencies in the VM while instantiating, since we already have them on our custom VM in either cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The rest of the notebook should be the same irrespective of whether you chose Option 1 or Option 2.\n",
    "\n",
    "**NOTE on $n\\_workers$ as a parameter:** The number of actual workers that our cluster would have is not always equal to the number of VMs spawned i.e. the value of $n\\_workers$ passed in. If the number of GPUs in the chosen `vm_size` is $G$ and number of VMs spawned is $n\\_workers$, then we have then number of actual workers $W = n\\_workers \\times G$. For example, for Standard_NC12s_v3 VMs that have 2 V100 GPUs per VM, for $n\\_workers=2$, we have $W = 2 \\times 2=4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating scheduler instance\n",
      "Assigned public IP\n",
      "Network interface ready\n",
      "Using Marketplace VM image with a Plan\n",
      "Creating VM\n",
      "Created VM dask-400ac9c4-scheduler\n",
      "Waiting for scheduler to run at 20.3.228.17:8786\n",
      "Scheduler is running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/contextlib.py:142: UserWarning: Creating your cluster is taking a surprisingly long time. This is likely due to pending resources. Hang tight! \n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating worker instance\n",
      "Creating worker instance\n",
      "Network interface ready\n",
      "Using Marketplace VM image with a Plan\n",
      "Creating VM\n",
      "Network interface ready\n",
      "Using Marketplace VM image with a Plan\n",
      "Creating VM\n",
      "Created VM dask-400ac9c4-worker-0cd31592\n",
      "Created VM dask-400ac9c4-worker-1838a39d\n",
      "CPU times: user 1.73 s, sys: 322 ms, total: 2.05 s\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cluster = AzureVMCluster(\n",
    "    location=location,\n",
    "    resource_group=resource_group,\n",
    "    vnet=vnet,\n",
    "    security_group=security_group,\n",
    "    vm_image=vm_image,\n",
    "    vm_size=vm_size,\n",
    "    disk_size=200,\n",
    "    docker_image=docker_image,\n",
    "    worker_class=worker_class,\n",
    "    n_workers=2,\n",
    "    security=True,\n",
    "    docker_args=docker_args,\n",
    "    debug=False,\n",
    "    bootstrap=False,  # This is to prevent the cloud init jinja2 script from running in the custom VM.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-33fe62ae-469a-11ee-a5fc-80e82cd32958</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_cloudprovider.AzureVMCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://20.3.228.17:8787/status\" target=\"_blank\">http://20.3.228.17:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">AzureVMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">10225ce5</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://20.3.228.17:8787/status\" target=\"_blank\">http://20.3.228.17:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 4\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 440.42 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-6aaec2fe-6997-48c2-89d8-faadcb29bdba</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://10.5.0.5:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.5.0.5:8787/status\" target=\"_blank\">http://10.5.0.5:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> 15 minutes ago\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 440.42 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: dask-400ac9c4-worker-0cd31592-0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.5.0.7:36717\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.5.0.7:32773/status\" target=\"_blank\">http://10.5.0.7:32773/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 110.11 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.5.0.7:43275\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-qwqxw8uf\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: dask-400ac9c4-worker-0cd31592-1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.5.0.7:33055\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.5.0.7:34773/status\" target=\"_blank\">http://10.5.0.7:34773/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 110.11 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.5.0.7:40845\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-vr1_9itb\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: dask-400ac9c4-worker-1838a39d-0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.5.0.6:38307\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.5.0.6:37659/status\" target=\"_blank\">http://10.5.0.6:37659/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 110.11 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.5.0.6:43501\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-v7juc99g\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: dask-400ac9c4-worker-1838a39d-1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.5.0.6:40869\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.5.0.6:45593/status\" target=\"_blank\">http://10.5.0.6:45593/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 110.11 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.5.0.6:36861\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-ql9rg3bd\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.5.0.5:8786' processes=4 threads=4, memory=440.42 GiB>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">AzureVMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">10225ce5</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://20.3.228.17:8787/status\" target=\"_blank\">http://20.3.228.17:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 4\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 440.42 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-6aaec2fe-6997-48c2-89d8-faadcb29bdba</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://10.5.0.5:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.5.0.5:8787/status\" target=\"_blank\">http://10.5.0.5:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> 15 minutes ago\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 440.42 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: dask-400ac9c4-worker-0cd31592-0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.5.0.7:36717\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.5.0.7:32773/status\" target=\"_blank\">http://10.5.0.7:32773/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 110.11 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.5.0.7:43275\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-qwqxw8uf\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: dask-400ac9c4-worker-0cd31592-1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.5.0.7:33055\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.5.0.7:34773/status\" target=\"_blank\">http://10.5.0.7:34773/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 110.11 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.5.0.7:40845\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-vr1_9itb\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: dask-400ac9c4-worker-1838a39d-0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.5.0.6:38307\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.5.0.6:37659/status\" target=\"_blank\">http://10.5.0.6:37659/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 110.11 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.5.0.6:43501\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-v7juc99g\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: dask-400ac9c4-worker-1838a39d-1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tls://10.5.0.6:40869\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://10.5.0.6:45593/status\" target=\"_blank\">http://10.5.0.6:45593/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 110.11 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tls://10.5.0.6:36861\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-ql9rg3bd\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU: </strong>Tesla V100-PCIE-16GB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>GPU memory: </strong> 16.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "AzureVMCluster(10225ce5, 'tls://20.3.228.17:8786', workers=4, threads=4, memory=440.42 GiB)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you only have the scheduler with n_workers=0 and want to scale the workers separately.\n",
    "# %%time\n",
    "# client.cluster.scale(n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait till all the workers are up. This will wait for `n_workers` number of VMs to be up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.52 ms, sys: 1.8 ms, total: 5.31 ms\n",
      "Wall time: 29.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "client.wait_for_workers(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the training process, let us take a quick look at the details of the GPUs in the worker pods that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': 'tls://10.5.0.5:8786',\n",
      " 'id': 'Scheduler-6aaec2fe-6997-48c2-89d8-faadcb29bdba',\n",
      " 'services': {'dashboard': 8787},\n",
      " 'started': 1693332941.4093616,\n",
      " 'type': 'Scheduler',\n",
      " 'workers': {'tls://10.5.0.6:38307': {'gpu': {'memory-total': 17179869184,\n",
      "                                              'name': 'Tesla V100-PCIE-16GB'},\n",
      "                                      'host': '10.5.0.6',\n",
      "                                      'id': 'dask-400ac9c4-worker-1838a39d-0',\n",
      "                                      'last_seen': 1693334115.716486,\n",
      "                                      'local_directory': '/tmp/dask-scratch-space/worker-v7juc99g',\n",
      "                                      'memory_limit': 118225672192,\n",
      "                                      'metrics': {'bandwidth': {'total': 100000000,\n",
      "                                                                'types': {},\n",
      "                                                                'workers': {}},\n",
      "                                                  'cpu': 2.0,\n",
      "                                                  'digests_total_since_heartbeat': {'latency': 0.00422215461730957,\n",
      "                                                                                    'tick-duration': 0.5002996921539307},\n",
      "                                                  'event_loop_interval': 0.02001443862915039,\n",
      "                                                  'gpu': {'memory-used': 598867968,\n",
      "                                                          'utilization': 0},\n",
      "                                                  'gpu_memory_used': 598867968,\n",
      "                                                  'gpu_utilization': 0,\n",
      "                                                  'host_disk_io': {'read_bps': 0.0,\n",
      "                                                                   'write_bps': 4285579.749180802},\n",
      "                                                  'host_net_io': {'read_bps': 7896.1441979567935,\n",
      "                                                                  'write_bps': 13579.687564157768},\n",
      "                                                  'managed_bytes': 0,\n",
      "                                                  'memory': 625389568,\n",
      "                                                  'num_fds': 86,\n",
      "                                                  'rmm': {'rmm-total': 0,\n",
      "                                                          'rmm-used': 0},\n",
      "                                                  'spilled_bytes': {'disk': 0,\n",
      "                                                                    'memory': 0},\n",
      "                                                  'task_counts': {},\n",
      "                                                  'time': 1693334115.2101967,\n",
      "                                                  'transfer': {'incoming_bytes': 0,\n",
      "                                                               'incoming_count': 0,\n",
      "                                                               'incoming_count_total': 0,\n",
      "                                                               'outgoing_bytes': 0,\n",
      "                                                               'outgoing_count': 0,\n",
      "                                                               'outgoing_count_total': 0}},\n",
      "                                      'name': 'dask-400ac9c4-worker-1838a39d-0',\n",
      "                                      'nanny': 'tls://10.5.0.6:43501',\n",
      "                                      'nthreads': 1,\n",
      "                                      'resources': {},\n",
      "                                      'services': {'dashboard': 37659},\n",
      "                                      'status': 'running',\n",
      "                                      'type': 'Worker'},\n",
      "             'tls://10.5.0.6:40869': {'gpu': {'memory-total': 17179869184,\n",
      "                                              'name': 'Tesla V100-PCIE-16GB'},\n",
      "                                      'host': '10.5.0.6',\n",
      "                                      'id': 'dask-400ac9c4-worker-1838a39d-1',\n",
      "                                      'last_seen': 1693334115.7172642,\n",
      "                                      'local_directory': '/tmp/dask-scratch-space/worker-ql9rg3bd',\n",
      "                                      'memory_limit': 118225672192,\n",
      "                                      'metrics': {'bandwidth': {'total': 100000000,\n",
      "                                                                'types': {},\n",
      "                                                                'workers': {}},\n",
      "                                                  'cpu': 0.0,\n",
      "                                                  'digests_total_since_heartbeat': {'latency': 0.0043697357177734375,\n",
      "                                                                                    'tick-duration': 0.49964427947998047},\n",
      "                                                  'event_loop_interval': 0.020003252029418946,\n",
      "                                                  'gpu': {'memory-used': 598867968,\n",
      "                                                          'utilization': 0},\n",
      "                                                  'gpu_memory_used': 598867968,\n",
      "                                                  'gpu_utilization': 0,\n",
      "                                                  'host_disk_io': {'read_bps': 0.0,\n",
      "                                                                   'write_bps': 4282769.5748925805},\n",
      "                                                  'host_net_io': {'read_bps': 7890.966475758198,\n",
      "                                                                  'write_bps': 13570.782983898314},\n",
      "                                                  'managed_bytes': 0,\n",
      "                                                  'memory': 622383104,\n",
      "                                                  'num_fds': 86,\n",
      "                                                  'rmm': {'rmm-total': 0,\n",
      "                                                          'rmm-used': 0},\n",
      "                                                  'spilled_bytes': {'disk': 0,\n",
      "                                                                    'memory': 0},\n",
      "                                                  'task_counts': {},\n",
      "                                                  'time': 1693334115.2123637,\n",
      "                                                  'transfer': {'incoming_bytes': 0,\n",
      "                                                               'incoming_count': 0,\n",
      "                                                               'incoming_count_total': 0,\n",
      "                                                               'outgoing_bytes': 0,\n",
      "                                                               'outgoing_count': 0,\n",
      "                                                               'outgoing_count_total': 0}},\n",
      "                                      'name': 'dask-400ac9c4-worker-1838a39d-1',\n",
      "                                      'nanny': 'tls://10.5.0.6:36861',\n",
      "                                      'nthreads': 1,\n",
      "                                      'resources': {},\n",
      "                                      'services': {'dashboard': 45593},\n",
      "                                      'status': 'running',\n",
      "                                      'type': 'Worker'},\n",
      "             'tls://10.5.0.7:33055': {'gpu': {'memory-total': 17179869184,\n",
      "                                              'name': 'Tesla V100-PCIE-16GB'},\n",
      "                                      'host': '10.5.0.7',\n",
      "                                      'id': 'dask-400ac9c4-worker-0cd31592-1',\n",
      "                                      'last_seen': 1693334115.5610104,\n",
      "                                      'local_directory': '/tmp/dask-scratch-space/worker-vr1_9itb',\n",
      "                                      'memory_limit': 118225670144,\n",
      "                                      'metrics': {'bandwidth': {'total': 100000000,\n",
      "                                                                'types': {},\n",
      "                                                                'workers': {}},\n",
      "                                                  'cpu': 2.0,\n",
      "                                                  'digests_total_since_heartbeat': {'latency': 0.003664255142211914,\n",
      "                                                                                    'tick-duration': 0.5014660358428955},\n",
      "                                                  'event_loop_interval': 0.019995880126953126,\n",
      "                                                  'gpu': {'memory-used': 598867968,\n",
      "                                                          'utilization': 0},\n",
      "                                                  'gpu_memory_used': 598867968,\n",
      "                                                  'gpu_utilization': 0,\n",
      "                                                  'host_disk_io': {'read_bps': 0.0,\n",
      "                                                                   'write_bps': 8389245.85113992},\n",
      "                                                  'host_net_io': {'read_bps': 612.0465351221121,\n",
      "                                                                  'write_bps': 4902.372737203585},\n",
      "                                                  'managed_bytes': 0,\n",
      "                                                  'memory': 624271360,\n",
      "                                                  'num_fds': 86,\n",
      "                                                  'rmm': {'rmm-total': 0,\n",
      "                                                          'rmm-used': 0},\n",
      "                                                  'spilled_bytes': {'disk': 0,\n",
      "                                                                    'memory': 0},\n",
      "                                                  'task_counts': {},\n",
      "                                                  'time': 1693334115.0549479,\n",
      "                                                  'transfer': {'incoming_bytes': 0,\n",
      "                                                               'incoming_count': 0,\n",
      "                                                               'incoming_count_total': 0,\n",
      "                                                               'outgoing_bytes': 0,\n",
      "                                                               'outgoing_count': 0,\n",
      "                                                               'outgoing_count_total': 0}},\n",
      "                                      'name': 'dask-400ac9c4-worker-0cd31592-1',\n",
      "                                      'nanny': 'tls://10.5.0.7:40845',\n",
      "                                      'nthreads': 1,\n",
      "                                      'resources': {},\n",
      "                                      'services': {'dashboard': 34773},\n",
      "                                      'status': 'running',\n",
      "                                      'type': 'Worker'},\n",
      "             'tls://10.5.0.7:36717': {'gpu': {'memory-total': 17179869184,\n",
      "                                              'name': 'Tesla V100-PCIE-16GB'},\n",
      "                                      'host': '10.5.0.7',\n",
      "                                      'id': 'dask-400ac9c4-worker-0cd31592-0',\n",
      "                                      'last_seen': 1693334115.5593781,\n",
      "                                      'local_directory': '/tmp/dask-scratch-space/worker-qwqxw8uf',\n",
      "                                      'memory_limit': 118225670144,\n",
      "                                      'metrics': {'bandwidth': {'total': 100000000,\n",
      "                                                                'types': {},\n",
      "                                                                'workers': {}},\n",
      "                                                  'cpu': 0.0,\n",
      "                                                  'digests_total_since_heartbeat': {'latency': 0.004190206527709961,\n",
      "                                                                                    'tick-duration': 0.5009698867797852},\n",
      "                                                  'event_loop_interval': 0.01999223232269287,\n",
      "                                                  'gpu': {'memory-used': 598867968,\n",
      "                                                          'utilization': 0},\n",
      "                                                  'gpu_memory_used': 598867968,\n",
      "                                                  'gpu_utilization': 0,\n",
      "                                                  'host_disk_io': {'read_bps': 0.0,\n",
      "                                                                   'write_bps': 8401951.8118285},\n",
      "                                                  'host_net_io': {'read_bps': 612.9735122727205,\n",
      "                                                                  'write_bps': 3345.312959135436},\n",
      "                                                  'managed_bytes': 0,\n",
      "                                                  'memory': 625373184,\n",
      "                                                  'num_fds': 86,\n",
      "                                                  'rmm': {'rmm-total': 0,\n",
      "                                                          'rmm-used': 0},\n",
      "                                                  'spilled_bytes': {'disk': 0,\n",
      "                                                                    'memory': 0},\n",
      "                                                  'task_counts': {},\n",
      "                                                  'time': 1693334115.0521584,\n",
      "                                                  'transfer': {'incoming_bytes': 0,\n",
      "                                                               'incoming_count': 0,\n",
      "                                                               'incoming_count_total': 0,\n",
      "                                                               'outgoing_bytes': 0,\n",
      "                                                               'outgoing_count': 0,\n",
      "                                                               'outgoing_count_total': 0}},\n",
      "                                      'name': 'dask-400ac9c4-worker-0cd31592-0',\n",
      "                                      'nanny': 'tls://10.5.0.7:43275',\n",
      "                                      'nthreads': 1,\n",
      "                                      'resources': {},\n",
      "                                      'services': {'dashboard': 32773},\n",
      "                                      'status': 'running',\n",
      "                                      'type': 'Worker'}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "pp.pprint(\n",
    "    client.scheduler_info()\n",
    ")  # will show some information of the GPUs of the workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#8735fb; font-size:22pt\"> Step 3: Data Setup, Cleanup and Enhancement </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#8735fb; font-size:18pt\"> Step 3.a: Set up the workers for reading parquet files from Azure Data Lake endpoints </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now enable all the workers to read the `parquet` files directly from the Azure Data Lake endpoints. This requires the [`adlfs`](https://github.com/dask/adlfs) python library in the workers. We will pass in the simple function `installAdlfs` in `client.run` which will install the python package in all the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tls://10.5.0.6:38307': {'status': 'OK'},\n",
       " 'tls://10.5.0.6:40869': {'status': 'OK'},\n",
       " 'tls://10.5.0.7:33055': {'status': 'OK'},\n",
       " 'tls://10.5.0.7:36717': {'status': 'OK'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import PipInstall\n",
    "\n",
    "client.register_worker_plugin(PipInstall(packages=[\"adlfs\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#8735fb; font-size:18pt\"> Step 3.b: Data Cleanup, Enhancement and Persisting Scripts </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to be cleaned up first. We remove some columns that we are not interested in. We also define the datatypes each of the columns need to be read as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add some new features to our dataframe via some custom functions, namely: \n",
    "1. Haversine distance: This is used for calculating the total trip distance.\n",
    "\n",
    "2. Day of the week: This can be useful information for determining the fare cost.\n",
    "\n",
    "`add_features` function combines the two to produce a new dataframe that has the added features.\n",
    "\n",
    "**NOTE:** In the function `persist_train_infer_split`, We will also persist the test dataset in the workers. If the `X_infer` i.e. the test dataset is small enough, we can call `compute()` on it to bring the test dataset to the local machine and then perform predict on it. But in general, if the `X_infer` is large, it may not fit in the GPU(s) of the local machine. Moreover, moving around a large amount of data will also add to the prediction latency. Therefore it is better to persist the test dataset on the dask workers, and then call the predict functionality on the individual workers. Finally we collect the prediction results from the dask workers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding features functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import cos, sin, asin, sqrt, pi\n",
    "\n",
    "\n",
    "def haversine_distance_kernel(\n",
    "    pickup_latitude_r,\n",
    "    pickup_longitude_r,\n",
    "    dropoff_latitude_r,\n",
    "    dropoff_longitude_r,\n",
    "    h_distance,\n",
    "    radius,\n",
    "):\n",
    "    for i, (x_1, y_1, x_2, y_2) in enumerate(\n",
    "        zip(\n",
    "            pickup_latitude_r,\n",
    "            pickup_longitude_r,\n",
    "            dropoff_latitude_r,\n",
    "            dropoff_longitude_r,\n",
    "        )\n",
    "    ):\n",
    "        x_1 = pi / 180 * x_1\n",
    "        y_1 = pi / 180 * y_1\n",
    "        x_2 = pi / 180 * x_2\n",
    "        y_2 = pi / 180 * y_2\n",
    "\n",
    "        dlon = y_2 - y_1\n",
    "        dlat = x_2 - x_1\n",
    "        a = sin(dlat / 2) ** 2 + cos(x_1) * cos(x_2) * sin(dlon / 2) ** 2\n",
    "\n",
    "        c = 2 * asin(sqrt(a))\n",
    "        # radius = 6371 # Radius of earth in kilometers # currently passed as input arguments\n",
    "\n",
    "        h_distance[i] = c * radius\n",
    "\n",
    "\n",
    "def day_of_the_week_kernel(day, month, year, day_of_week):\n",
    "    for i, (d_1, m_1, y_1) in enumerate(zip(day, month, year)):\n",
    "        if month[i] < 3:\n",
    "            shift = month[i]\n",
    "        else:\n",
    "            shift = 0\n",
    "        Y = year[i] - (month[i] < 3)\n",
    "        y = Y - 2000\n",
    "        c = 20\n",
    "        d = day[i]\n",
    "        m = month[i] + shift + 1\n",
    "        day_of_week[i] = (d + math.floor(m * 2.6) + y + (y // 4) + (c // 4) - 2 * c) % 7\n",
    "\n",
    "\n",
    "def add_features(df):\n",
    "    df[\"hour\"] = df[\"tpepPickupDateTime\"].dt.hour\n",
    "    df[\"year\"] = df[\"tpepPickupDateTime\"].dt.year\n",
    "    df[\"month\"] = df[\"tpepPickupDateTime\"].dt.month\n",
    "    df[\"day\"] = df[\"tpepPickupDateTime\"].dt.day\n",
    "    df[\"diff\"] = (\n",
    "        df[\"tpepDropoffDateTime\"] - df[\"tpepPickupDateTime\"]\n",
    "    ).dt.seconds  # convert difference between pickup and dropoff into seconds\n",
    "\n",
    "    df[\"pickup_latitude_r\"] = df[\"startLat\"] // 0.01 * 0.01\n",
    "    df[\"pickup_longitude_r\"] = df[\"startLon\"] // 0.01 * 0.01\n",
    "    df[\"dropoff_latitude_r\"] = df[\"endLat\"] // 0.01 * 0.01\n",
    "    df[\"dropoff_longitude_r\"] = df[\"endLon\"] // 0.01 * 0.01\n",
    "\n",
    "    df = df.drop(\"tpepDropoffDateTime\", axis=1)\n",
    "    df = df.drop(\"tpepPickupDateTime\", axis=1)\n",
    "\n",
    "    df = df.apply_rows(\n",
    "        haversine_distance_kernel,\n",
    "        incols=[\n",
    "            \"pickup_latitude_r\",\n",
    "            \"pickup_longitude_r\",\n",
    "            \"dropoff_latitude_r\",\n",
    "            \"dropoff_longitude_r\",\n",
    "        ],\n",
    "        outcols=dict(h_distance=np.float32),\n",
    "        kwargs=dict(radius=6371),\n",
    "    )\n",
    "\n",
    "    df = df.apply_rows(\n",
    "        day_of_the_week_kernel,\n",
    "        incols=[\"day\", \"month\", \"year\"],\n",
    "        outcols=dict(day_of_week=np.float32),\n",
    "        kwargs=dict(),\n",
    "    )\n",
    "\n",
    "    df[\"is_weekend\"] = df[\"day_of_week\"] < 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for cleaning and persisting the data in the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "library/cuml",
     "library/dask-cudf",
     "library/numpy",
     "library/dask",
     "tools/dask-cloudprovider",
     "cloud/azure/azure-vm",
     "dataset/nyc-taxi",
     "data-format/parquet",
     "data-storage/adls"
    ]
   },
   "outputs": [],
   "source": [
    "def persist_train_infer_split(\n",
    "    client,\n",
    "    df,\n",
    "    response_dtype,\n",
    "    response_id,\n",
    "    infer_frac=1.0,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "):\n",
    "    workers = client.has_what().keys()\n",
    "    X, y = df.drop([response_id], axis=1), df[response_id].astype(\"float32\")\n",
    "    infer_frac = max(0, min(infer_frac, 1.0))\n",
    "    X_train, X_infer, y_train, y_infer = train_test_split(\n",
    "        X, y, shuffle=True, random_state=random_state, test_size=infer_frac\n",
    "    )\n",
    "\n",
    "    with dask.annotate(workers=set(workers)):\n",
    "        X_train, y_train = client.persist(collections=[X_train, y_train])\n",
    "\n",
    "    if infer_frac != 1.0:\n",
    "        with dask.annotate(workers=set(workers)):\n",
    "            X_infer, y_infer = client.persist(collections=[X_infer, y_infer])\n",
    "\n",
    "        wait([X_train, y_train, X_infer, y_infer])\n",
    "    else:\n",
    "        X_infer = X_train\n",
    "        y_infer = y_train\n",
    "\n",
    "        wait([X_train, y_train])\n",
    "\n",
    "    return X_train, y_train, X_infer, y_infer\n",
    "\n",
    "\n",
    "def clean(df_part, must_haves):\n",
    "    \"\"\"\n",
    "    This function performs the various clean up tasks for the data\n",
    "    and returns the cleaned dataframe.\n",
    "    \"\"\"\n",
    "    # iterate through columns in this df partition\n",
    "    for col in df_part.columns:\n",
    "        # drop anything not in our expected list\n",
    "        if col not in must_haves:\n",
    "            df_part = df_part.drop(col, axis=1)\n",
    "            continue\n",
    "\n",
    "        # fixes datetime error found by Ty Mckercher and fixed by Paul Mahler\n",
    "        if df_part[col].dtype == \"object\" and col in [\n",
    "            \"tpepPickupDateTime\",\n",
    "            \"tpepDropoffDateTime\",\n",
    "        ]:\n",
    "            df_part[col] = df_part[col].astype(\"datetime64[ms]\")\n",
    "            continue\n",
    "\n",
    "        # if column was read as a string, recast as float\n",
    "        if df_part[col].dtype == \"object\":\n",
    "            df_part[col] = df_part[col].str.fillna(\"-1\")\n",
    "            df_part[col] = df_part[col].astype(\"float32\")\n",
    "        else:\n",
    "            # downcast from 64bit to 32bit types\n",
    "            # Tesla T4 are faster on 32bit ops\n",
    "            if \"int\" in str(df_part[col].dtype):\n",
    "                df_part[col] = df_part[col].astype(\"int32\")\n",
    "            if \"float\" in str(df_part[col].dtype):\n",
    "                df_part[col] = df_part[col].astype(\"float32\")\n",
    "            df_part[col] = df_part[col].fillna(-1)\n",
    "\n",
    "    return df_part\n",
    "\n",
    "\n",
    "def taxi_data_loader(\n",
    "    client,\n",
    "    adlsaccount,\n",
    "    adlspath,\n",
    "    response_dtype=np.float32,\n",
    "    infer_frac=1.0,\n",
    "    random_state=0,\n",
    "):\n",
    "    # create a list of columns & dtypes the df must have\n",
    "    must_haves = {\n",
    "        \"tpepPickupDateTime\": \"datetime64[ms]\",\n",
    "        \"tpepDropoffDateTime\": \"datetime64[ms]\",\n",
    "        \"passengerCount\": \"int32\",\n",
    "        \"tripDistance\": \"float32\",\n",
    "        \"startLon\": \"float32\",\n",
    "        \"startLat\": \"float32\",\n",
    "        \"rateCodeId\": \"int32\",\n",
    "        \"endLon\": \"float32\",\n",
    "        \"endLat\": \"float32\",\n",
    "        \"fareAmount\": \"float32\",\n",
    "    }\n",
    "\n",
    "    workers = client.has_what().keys()\n",
    "    response_id = \"fareAmount\"\n",
    "    storage_options = {\"account_name\": adlsaccount}\n",
    "    taxi_data = dask_cudf.read_parquet(\n",
    "        adlspath,\n",
    "        storage_options=storage_options,\n",
    "        chunksize=25e6,\n",
    "        npartitions=len(workers),\n",
    "    )\n",
    "    taxi_data = clean(taxi_data, must_haves)\n",
    "    taxi_data = taxi_data.map_partitions(add_features)\n",
    "    # Drop NaN values and convert to float32\n",
    "    taxi_data = taxi_data.dropna()\n",
    "    fields = [\n",
    "        \"passengerCount\",\n",
    "        \"tripDistance\",\n",
    "        \"startLon\",\n",
    "        \"startLat\",\n",
    "        \"rateCodeId\",\n",
    "        \"endLon\",\n",
    "        \"endLat\",\n",
    "        \"fareAmount\",\n",
    "        \"diff\",\n",
    "        \"h_distance\",\n",
    "        \"day_of_week\",\n",
    "        \"is_weekend\",\n",
    "    ]\n",
    "    taxi_data = taxi_data.astype(\"float32\")\n",
    "    taxi_data = taxi_data[fields]\n",
    "    taxi_data = taxi_data.reset_index()\n",
    "\n",
    "    return persist_train_infer_split(\n",
    "        client, taxi_data, response_dtype, response_id, infer_frac, random_state\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#8735fb; font-size:18pt\"> Step 3.c: Get the split data and persist across workers </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of the data from November and December 2014 for the purposes of the demo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skirui/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/dask/dataframe/io/parquet/core.py:411: FutureWarning: The `chunksize` argument is deprecated, and will be removed in a future release. Setting the `blocksize` argument instead. Please see documentation on the `blocksize` argument for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: Error during deserialization of the task graph. This frequently occurs if the Scheduler and Client have different environments. For more information, see https://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/distributed/scheduler.py:4346\u001b[0m, in \u001b[0;36mupdate_graph\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/distributed/protocol/serialize.py:432\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/distributed/protocol/serialize.py:98\u001b[0m, in \u001b[0;36mpickle_loads\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/distributed/protocol/pickle.py:94\u001b[0m, in \u001b[0;36mloads\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'adlfs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/dask/backends.py:136\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/dask/dataframe/io/parquet/core.py:543\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, filters, categories, index, storage_options, engine, use_nullable_dtypes, dtype_backend, calculate_divisions, ignore_metadata_file, metadata_task_size, split_row_groups, blocksize, aggregate_files, parquet_file_extension, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m     blocksize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m read_metadata_result \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgather_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalculate_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_row_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_row_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregate_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregate_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_metadata_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_metadata_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_task_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_task_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparquet_file_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparquet_file_extension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# In the future, we may want to give the engine the\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# option to return a dedicated element for `common_kwargs`.\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# However, to avoid breaking the API, we just embed this\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# data in the first element of `parts` for now.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# The logic below is inteded to handle backward and forward\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# compatibility with a user-defined engine.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/dask/dataframe/io/parquet/arrow.py:554\u001b[0m, in \u001b[0;36mArrowDatasetEngine.read_metadata\u001b[0;34m(cls, fs, paths, categories, index, use_nullable_dtypes, dtype_backend, gather_statistics, filters, split_row_groups, blocksize, aggregate_files, ignore_metadata_file, metadata_task_size, parquet_file_extension, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# Stage 3: Generate parts and stats\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m parts, stats, common_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_collection_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# Add `common_kwargs` and `aggregation_depth` to the first\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# element of `parts`. We can return as a separate element\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# in the future, but should avoid breaking the API for now.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/dask/dataframe/io/parquet/arrow.py:1483\u001b[0m, in \u001b[0;36mArrowDatasetEngine._construct_collection_plan\u001b[0;34m(cls, dataset_info)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         gather_parts_dsk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name] \u001b[38;5;241m=\u001b[39m (_combine_parts, finalize_list)\n\u001b[0;32m-> 1483\u001b[0m         parts, stats \u001b[38;5;241m=\u001b[39m \u001b[43mDelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinal-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgather_parts_dsk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parts, stats, common_kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/dask/base.py:381\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03mThis turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/dask/base.py:666\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 666\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/distributed/client.py:3259\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3258\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3259\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/distributed/client.py:2384\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m    \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/distributed/utils.py:359\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/distributed/utils.py:426\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/distributed/utils.py:399\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    398\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 399\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/tornado/gen.py:767\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;66;03m# Save the exception for later. It's important that\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;66;03m# gen.throw() not be called inside this try/except block\u001b[39;00m\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;66;03m# because that makes sys.exc_info behave unexpectedly.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/distributed/client.py:2247\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m   2248\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error during deserialization of the task graph. This frequently occurs if the Scheduler and Client have different environments. For more information, see https://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tic \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m----> 2\u001b[0m X_train, y_train, X_infer, y_infer \u001b[38;5;241m=\u001b[39m \u001b[43mtaxi_data_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43madlsaccount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mazureopendatastorage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43madlspath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maz://nyctlc/yellow/puYear=2014/puMonth=1*/*.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m toc \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWall clock time taken for ETL and persisting : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoc\u001b[38;5;241m-\u001b[39mtic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 95\u001b[0m, in \u001b[0;36mtaxi_data_loader\u001b[0;34m(client, adlsaccount, adlspath, response_dtype, infer_frac, random_state)\u001b[0m\n\u001b[1;32m     93\u001b[0m response_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfareAmount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m storage_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccount_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: adlsaccount}\n\u001b[0;32m---> 95\u001b[0m taxi_data \u001b[38;5;241m=\u001b[39m \u001b[43mdask_cudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43madlspath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25e6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnpartitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m taxi_data \u001b[38;5;241m=\u001b[39m clean(taxi_data, must_haves)\n\u001b[1;32m    102\u001b[0m taxi_data \u001b[38;5;241m=\u001b[39m taxi_data\u001b[38;5;241m.\u001b[39mmap_partitions(add_features)\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/dask_cudf/io/parquet.py:539\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    537\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_file_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m check_file_size\n\u001b[0;32m--> 539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCudfEngine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rapids-23.08/lib/python3.10/site-packages/dask/backends.py:138\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod registered to the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m backend.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: An error occurred while calling the read_parquet method registered to the pandas backend.\nOriginal Message: Error during deserialization of the task graph. This frequently occurs if the Scheduler and Client have different environments. For more information, see https://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments\n"
     ]
    }
   ],
   "source": [
    "tic = timer()\n",
    "X_train, y_train, X_infer, y_infer = taxi_data_loader(\n",
    "    client,\n",
    "    adlsaccount=\"azureopendatastorage\",\n",
    "    adlspath=\"az://nyctlc/yellow/puYear=2014/puMonth=1*/*.parquet\",\n",
    "    infer_frac=0.1,\n",
    "    random_state=42,\n",
    ")\n",
    "toc = timer()\n",
    "print(f\"Wall clock time taken for ETL and persisting : {toc-tic} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of our training dataset is around 49 million rows. Let's look at the data locally to see what we're dealing with. We see that there are columns for pickup and dropoff latitude and longitude, passenger count, trip distance, day of week etc. These are the information we'll use to estimate the trip fare amount. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <span style=\"color:#8735fb; font-size:22pt\"> Step 4: Train a XGBoost Model </span>\n",
    "\n",
    "We are now ready to train a XGBoost model on the data and then predict the fare for each trip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#8735fb; font-size:18pt\"> Step 4.a: Set training Parameters </span>\n",
    "\n",
    "In this training example, we will use RMSE as the evaluation metric. It is also worth noting that performing HPO will lead to a set of more optimal hyperparameters.\n",
    "\n",
    "Refer to the notebook [HPO-RAPIDS](./HPO-RAPIDS.ipynb) in this repository for how to perform HPO on Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.15,\n",
    "    \"max_depth\": 8,\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 1,\n",
    "    \"silent\": True,\n",
    "    \"verbose_eval\": True,\n",
    "    \"booster\": \"gbtree\",  # 'gblinear' not implemented in dask\n",
    "    \"debug_synchronize\": True,\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"num_boost_rounds\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#8735fb; font-size:18pt\"> Step 4.b: Train XGBoost Model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is already persisted in the dask workers in the cluster, the next steps should not take a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = xgb.dask.DaskDMatrix(client, X_train, y_train)\n",
    "tic = timer()\n",
    "xgboost_output = xgb.dask.train(\n",
    "    client, params, data_train, num_boost_round=params[\"num_boost_rounds\"]\n",
    ")\n",
    "xgb_gpu_model = xgboost_output[\"booster\"]\n",
    "toc = timer()\n",
    "print(f\"Wall clock time taken for this cell : {toc-tic} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#8735fb; font-size:18pt\"> Step 4.c: Save the trained model to disk locally </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = \"trained-model_nyctaxi.xgb\"\n",
    "xgb_gpu_model.save_model(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <span style=\"color:#8735fb; font-size:22pt\"> Step 5: Predict & Score using vanilla XGBoost Predict </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Here we will use the `predict` and `inplace_predict` methods provided by the `xgboost.dask` library, out of the box. Later we will also use [Forest Inference Library (FIL)](https://docs.rapids.ai/api/cuml/stable/api.html?highlight=forestinference#cuml.ForestInference) to perform prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y_test = y_infer.compute()\n",
    "wait(_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.dask.DaskDMatrix(client, X_infer)\n",
    "tic = timer()\n",
    "y_pred = xgb.dask.predict(client, xgb_gpu_model, d_test)\n",
    "y_pred = y_pred.compute()\n",
    "wait(y_pred)\n",
    "toc = timer()\n",
    "print(f\"Wall clock time taken for xgb.dask.predict : {toc-tic} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Inference with the inplace predict method of dask XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timer()\n",
    "y_pred = xgb.dask.inplace_predict(client, xgb_gpu_model, X_infer)\n",
    "y_pred = y_pred.compute()\n",
    "wait(y_pred)\n",
    "toc = timer()\n",
    "print(f\"Wall clock time taken for inplace inference : {toc-tic} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tic = timer()\n",
    "print(\"Calculating MSE\")\n",
    "score = mean_squared_error(y_pred, _y_test)\n",
    "print(\"Workflow Complete - RMSE: \", np.sqrt(score))\n",
    "toc = timer()\n",
    "print(f\"Wall clock time taken for this cell : {toc-tic} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#8735fb; font-size:22pt\"> Step 6: Predict & Score using FIL or Forest Inference Library </span>\n",
    "\n",
    "[Forest Inference Library (FIL)](https://docs.rapids.ai/api/cuml/stable/api.html?highlight=forestinference#cuml.ForestInference) provides GPU accelerated inference capabilities for tree models. We will import the FIL functionality from [cuML](https://github.com/rapidsai/cuml) library.\n",
    "\n",
    "It accepts a **trained** tree model in a treelite format (currently LightGBM, XGBoost and SKLearn GBDT and random forest models\n",
    "are supported). In general, using FIL allows for faster inference while using a large number of workers, and the latency benefits are more pronounced as the size of the dataset grows large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import ForestInference\n",
    "from dask.distributed import get_worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#8735fb; font-size:18pt\"> Step 6.a: Predict using `compute` on a single worker in case the test dataset is small. </span>\n",
    "\n",
    "As noted in *Step 3.b*,  in case the test dataset is huge, it makes sense to call predict individually on the dask workers instead of bringing the entire test dataset to the local machine.\n",
    "\n",
    "To perform prediction individually on the dask workers, each dask worker needs to load the XGB model using FIL. However, the dask workers are remote and do not have access to the locally saved model. Hence we need to send the locally saved XGB model to the dask workers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = client.has_what().keys()\n",
    "print(workers)\n",
    "n_workers = len(workers)\n",
    "n_partitions = n_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipFile(zipname):\n",
    "    worker = get_worker()\n",
    "    import zipfile\n",
    "    import os\n",
    "\n",
    "    with zipfile.ZipFile(os.path.join(worker.local_directory, zipname)) as zf:\n",
    "        zf.extractall(worker.local_directory)\n",
    "\n",
    "\n",
    "def checkOrMakeLocalDir():\n",
    "    worker = get_worker()\n",
    "    import os\n",
    "\n",
    "    if not os.path.exists(worker.local_directory):\n",
    "        os.makedirs(worker.local_directory)\n",
    "\n",
    "\n",
    "def workerModelInit(model_file):\n",
    "    # this function will run in each worker and initialize the worker\n",
    "    import os\n",
    "\n",
    "    worker = get_worker()\n",
    "    worker.data[\"fil_model\"] = ForestInference.load(\n",
    "        filename=os.path.join(worker.local_directory, model_file), model_type=\"xgboost\"\n",
    "    )\n",
    "    worker.data[\"fil_model\"]\n",
    "\n",
    "\n",
    "def predict(input_df):\n",
    "    # this function will run in each worker and predict\n",
    "    worker = get_worker()\n",
    "    return worker.data[\"fil_model\"].predict(input_df)\n",
    "\n",
    "\n",
    "def persistModelonWorkers(client, zip_file_name, model_file_name):\n",
    "    import zipfile\n",
    "\n",
    "    zf = zipfile.ZipFile(zip_file_name, mode=\"w\")\n",
    "    zf.write(f\"./{model_file_name}\")\n",
    "    zf.close()\n",
    "    # check to see if local directory present in workers\n",
    "    # if not present make it\n",
    "    fut = client.submit(checkOrMakeLocalDir)\n",
    "    wait(fut)\n",
    "    # upload the zip file in workers\n",
    "    fut = client.upload_file(f\"./{zip_file_name}\")\n",
    "    wait(fut)\n",
    "    # unzip file in the workers\n",
    "    fut = client.submit(unzipFile, zip_file_name)\n",
    "    wait(fut)\n",
    "    # load model using FIL in workers\n",
    "    fut = client.submit(workerModelInit, model_file_name)\n",
    "    wait(fut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persist the local model in the remote dask workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "persistModelonWorkers(client, \"zipfile_write.zip\", \"trained-model_nyctaxi.xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference with distributed predict with FIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = timer()\n",
    "predictions = X_infer.map_partitions(predict, meta=\"float\")  # this is like MPI reduce\n",
    "y_pred = predictions.compute()\n",
    "wait(y_pred)\n",
    "toc = timer()\n",
    "print(f\"Wall clock time taken for this cell : {toc-tic} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_csv = X_infer.iloc[:, 0].shape[0].compute()\n",
    "print(\n",
    "    f\"It took {toc-tic} seconds to predict on {rows_csv} rows using FIL distributedly on each worker\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tic = timer()\n",
    "score = mean_squared_error(y_pred, _y_test)\n",
    "toc = timer()\n",
    "print(\"Final - RMSE: \", np.sqrt(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## <span style=\"color:#8735fb; font-size:22pt\"> Step 7: Clean up </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.08",
   "language": "python",
   "name": "rapids-23.08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
