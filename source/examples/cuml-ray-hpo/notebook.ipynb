{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a930ecf7",
   "metadata": {},
   "source": [
    "# HPO for Random Forest with Ray Tune and cuML\n",
    "\n",
    "This notebook demonstrates how to perform hyperparameter optimization (HPO) for a Random Forest classifier using Ray Tune and cuML. We'll use Ray Tune to efficiently search through hyperparameter combinations while leveraging cuML's GPU-accelerated Random Forest implementation for faster training.\n",
    "\n",
    "## Problem Overview\n",
    "\n",
    "We're solving a binary classification problem using the airline dataset, where we predict flight delays. The goal is to find the optimal hyperparameters (number of estimators, max depth, and max features) that maximize the model's accuracy. Ray Tune will orchestrate multiple training trials in parallel, each testing different hyperparameter combinations, while cuML provides GPU acceleration for each individual model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee88f22",
   "metadata": {},
   "source": [
    "### Setup Instructions\n",
    "\n",
    "#### Brev\n",
    "\n",
    "```{docref} /cloud/nvidia/brev\n",
    "For the purpose of this example, follow Option 1 (Setting up your Brev GPU Environment) in the Brev Instance Setup section:\n",
    "- Create a GPU environment with 4 L4 GPUs\n",
    "- Make sure to include Jupyter in your setup\n",
    "- Wait until the \"Open Notebook\" button is flashing\n",
    "- Open the Notebook and navigate to a Jupyter terminal\n",
    "```\n",
    "\n",
    "#### Environment Setup with uv (included in Brev)\n",
    "\n",
    "1. Check Your CUDA Version in the Jupyter terminal\n",
    "\n",
    "Before installing dependencies, verify your CUDA version (shown in the top right corner of the output):\n",
    "\n",
    "```bash\n",
    "nvidia-smi\n",
    "```\n",
    "\n",
    "2. Create a file named `pyproject.toml` and copy the content below\n",
    "\n",
    "Based on your CUDA version you have, modify the `cuML` package:\n",
    "\n",
    "- **CUDA 12.x**: Use `cuml-cu12==26.2.*`\n",
    "- **CUDA 13.x**: Change to `cuml-cu13==26.2.*`\n",
    "\n",
    "> **TODO (BLOCKED)**: CuPy 13 requires a system CUDA install (or conda, but not relevant here). CuPy 14 is releasing soon and properly supports installations with only CUDA wheels. This support will come via the cuda-pathfinder project. Once CuPy 14 is out, upgrading it in an existing cuML environment would patch this (e.g., having cuML or cuDF 26.02 but bumping CuPy in your own env). Existing RAPIDS packages pin `cupy>=13.6`, which would resolve to 14 in a new environment or upgrade. This will be autofixed, effectively. Unfortunately, Brev doesn't have a system CUDA installed, or at least is not in GCP machines.\n",
    "\n",
    "The `pyproject.toml` file should look like this:\n",
    "\n",
    "```toml\n",
    "[project]\n",
    "name = \"ray-cuml\"\n",
    "version = \"0.1.0\"\n",
    "requires-python = \"==3.13.*\"\n",
    "dependencies = [\n",
    "    \"ray[default]==2.53.0\",\n",
    "    \"ray[data]==2.53.0\",\n",
    "    \"ray[train]==2.53.0\",\n",
    "    \"ray[tune]==2.53.0\",\n",
    "    \"cuml-cu12==26.2.*\",  # Change cu12 to cu13 if you have CUDA 13.x\n",
    "    \"jupyterlab-nvdashboard\",\n",
    "    \"ipykernel\",\n",
    "]\n",
    "```\n",
    "\n",
    "3. Install Dependencies\n",
    "\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "\n",
    "#### Enable Jupyter nvdashboard\n",
    "\n",
    "We can use the `jupyterlab-nvdashboard` extension monitor GPU usage in Jupyter\n",
    "\n",
    "To be able to enable the `nvdashboard` jupyter extension, installed in as part of the setup, \n",
    "\n",
    "1. Restart Jupyter: `sudo systemctl restart jupyter.service`\n",
    "2. Exit and reopen the notebook or refresh your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee8292",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Open a new notebook to get started with this example.\n",
    "\n",
    "You should now see a button on the left panel that looks like a GPU, which will give you several dashboards to choose from. For the sake of this example, we will look at GPU memory and GPU Utilization.\n",
    "\n",
    "![GPU Dashboard Button](../../_static/images/examples/cuml-ray-hpo/nvdashboard.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28930e22",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Copy the `get_data.py` script provided in the `setup` directory to your current jupyter working directory.\n",
    "\n",
    "Download the airline dataset. The script supports both a small dataset (for quick testing) and a full dataset (20M rows). By default, it downloads the small dataset. Use the `--full-dataset` flag for the complete dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497cff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python get_data.py --full-dataset ## for a smaller dataset remove --full-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ray\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from cuml.metrics import accuracy_score\n",
    "from ray import tune\n",
    "from ray.tune import RunConfig, TuneConfig\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa20b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(config, data_dict):\n",
    "    \"\"\"\n",
    "    Training function for Ray Tune.\n",
    "\n",
    "    Args:\n",
    "        config: Dictionary of hyperparameters from Ray Tune\n",
    "        data_dict: Dictionary containing training and test data (NumPy arrays)\n",
    "    \"\"\"\n",
    "    # Extract data\n",
    "    X_train = data_dict[\"X_train\"]\n",
    "    X_test = data_dict[\"X_test\"]\n",
    "    y_train = data_dict[\"y_train\"]\n",
    "    y_test = data_dict[\"y_test\"]\n",
    "\n",
    "    # Initialize cuML Random Forest with hyperparameters from config\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=config[\"n_estimators\"],\n",
    "        max_depth=config[\"max_depth\"],\n",
    "        max_features=config[\"max_features\"],\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    predictions = rf.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy using cuML's metric function\n",
    "    score = accuracy_score(y_test, predictions)\n",
    "\n",
    "    # Report metrics back to Ray Tune\n",
    "    return {\"accuracy\": score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fce0d3",
   "metadata": {},
   "source": [
    "## Ray Tune Hyperparameter Search\n",
    "\n",
    "Now we'll set up Ray Tune to search for optimal hyperparameters. Ray Tune will run multiple trials in parallel, each testing different combinations of hyperparameters. Each trial will train a cuML Random Forest model on a GPU and evaluate its performance.\n",
    "\n",
    "**Important**: Modify the following according to your setup:\n",
    "- `ray.init()` parameters: Adjust `num_cpus` and `num_gpus` based on your available resources if you are not using the Brev instance indicated. \n",
    "- `storage_path` in `RunConfig`: Set a valid local path to save Ray Tune results\n",
    "- `resources` in `tune.with_resources()`: Configure CPU and GPU allocation per trial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ray with resource constraints\n",
    "# Note: If you see a FutureWarning about RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO, that's okay -\n",
    "# it's just informing you about future Ray behavior changes and doesn't affect functionality.\n",
    "ray.init(num_cpus=8, num_gpus=4)\n",
    "\n",
    "# use airlines_small.parquet if you downloaded the small dataset\n",
    "df = pd.read_parquet(\"data/airlines.parquet\")\n",
    "\n",
    "# Define the target label\n",
    "label = \"ArrDelayBinary\"\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop(columns=[label])  # All columns except the target\n",
    "y = df[label]  # Just the target column\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TODO CHECK IF WE SHOULD CONVERT TO NUMPY ARRAYS FOR Ray Tune FOR zero copy efficiency on CPU?\n",
    "# https://docs.ray.io/en/latest/ray-core/objects.html#fetching-object-data\n",
    "\n",
    "# Store data in a dictionary to pass to training function\n",
    "data_dict = {\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3cf300",
   "metadata": {},
   "source": [
    "**Access Ray Dashboard**: The dashboard is available at `http://127.0.0.1:8265` on the Brev instance. To access it from your local machine, run in your local terminal:\n",
    "\n",
    "```bash\n",
    "brev port-forward <your-instance-name> -p 8265:8265\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define hyperparameter search space\n",
    "search_space = {\n",
    "    \"n_estimators\": tune.grid_search([25, 50, 75, 100]),\n",
    "    \"max_depth\": tune.grid_search([10, 20, 30, 40]),\n",
    "    \"max_features\": tune.grid_search([0.25, 0.5, 0.75, 1.0]),\n",
    "}\n",
    "\n",
    "# Using default random search algorithm\n",
    "tune_config = TuneConfig(\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "run_config = RunConfig(\n",
    "    name=\"rf_hyperparameter_tuning_real_data\",\n",
    "    storage_path=os.path.abspath(\"<your-path>/ray_results\"),\n",
    ")\n",
    "\n",
    "# Create a trainable with resources\n",
    "trainable = tune.with_resources(\n",
    "    tune.with_parameters(train_rf, data_dict=data_dict),\n",
    "    resources={\"cpu\": 2, \"gpu\": 1},  # Each trial uses 1 GPU and 2 CPUs\n",
    ")\n",
    "\n",
    "# Run the hyperparameter tuning\n",
    "tuner = tune.Tuner(\n",
    "    trainable,\n",
    "    param_space=search_space,\n",
    "    tune_config=tune_config,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "\n",
    "# Get the best result\n",
    "best_result = results.get_best_result(metric=\"accuracy\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(f\"  n_estimators: {best_result.config['n_estimators']}\")\n",
    "print(f\"  max_depth: {best_result.config['max_depth']}\")\n",
    "print(f\"  max_features: {best_result.config['max_features']}\")\n",
    "print(f\"Best test accuracy: {best_result.metrics['accuracy']:.4f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up Ray results directory\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "ray_results_path = \"<local_path_to_save_results>/ray_results\"\n",
    "if os.path.exists(ray_results_path):\n",
    "    print(f\"Cleaning Ray results directory: {ray_results_path}\")\n",
    "    shutil.rmtree(ray_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ad5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown Ray\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
