# GitHub Actions

GitHub Actions is a popular way to automatically run tests against code hosted on GitHub.

GitHub's free tier includes basic runners (the machines that will run your code) and the paid tier includes support for [hosted runners with NVIDIA GPUs](https://github.blog/changelog/2024-07-08-github-actions-gpu-hosted-runners-are-now-generally-available/). This allows GPU specific code to be exercised as part of a CI workflow.

## Cost

As GPU runners are not included in the free tier projects will have to pay for GPU CI resources. Typically GPU runners cost a few cents per minute, check out the [GitHub documentation](https://docs.github.com/en/billing/managing-billing-for-github-actions/about-billing-for-github-actions#per-minute-rates-for-gpu-powered-larger-runners) for more information.

We recommend that projects set a [spending limit](https://docs.github.com/en/billing/managing-billing-for-github-actions/about-billing-for-github-actions#about-spending-limits) on their account/organization. That way your monthly bill will never be a surprise.

We also recommend that you only run GPU CI intentionally rather than on every pull request from every contributor. Check out the best practices section for more information.

## Getting started

### Setting up your GPU runners

First you'll need to set up a way to pay GitHub. You can do this by [adding a payment method](https://docs.github.com/en/billing/managing-your-github-billing-settings/adding-or-editing-a-payment-method) to your organisation.

While you're in your billing settings you should also decide what the maximum is that you wish to spend on GPU CI functionality and then set a [spending limit](https://docs.github.com/en/billing/managing-billing-for-github-actions/managing-your-spending-limit-for-github-actions) on your account.

Next you can go into the GitHub Actions settings for your account and configure a [larger runner](https://docs.github.com/en/actions/using-github-hosted-runners/using-larger-runners/about-larger-runners). You can find this settings page by visiting `https://github.com/organizations/<YOUR_ORG>/settings/actions/runners`.

![Screenshot of the GitHub Actions runner configuration page with the new runner button highlighted](/_static/images/developer/ci/github-actions/new-hosted-runner.png)

Next you need to give your runner a name, for example `linux-nvidia-gpu`, you'll need to remember this for configuring your workflows later. Then you need to choose your runner settings:

- Under "Platform" select "Linux x64"
- Under "Image" switch to the "Partner" tab and choose "NVIDIA GPU-Optimized Image for AI and HPC"
- Under "Size" switch to the "GPU-powered" tab and select your preferred NVIDIA hardware

![Screenshot of the GitHub Actions runner configuration page a new GPU runner configured](/_static/images/developer/ci/github-actions/new-runner-config.png)

Then set your preferred maximum concurrency and then choose "Create runner".

### Configuring your workflows

To configure your workflow to use your new GPU runners you need to set the `runs-on` property to match the name you gave the runner group.

```yaml
name: GitHub Actions GPU Demo
run-name: ${{ github.actor }} is testing out GPU GitHub Actions ðŸš€
on: [push]
jobs:
  gpu-workflow:
    runs-on: linux-nvidia-gpu
    steps:
      - name: Check GPU is available
        run: nvidia-smi
```

## Best practices

Adding GitHub Actions runners to your project that cost money requires you to put some extra thought into when you want those workflows to run. Setting a spending cap allows you to keep control of how much you are spending, but you still want to get the most for your money. Here are some tips on when to effectively use GPU runners in your projects.

### Use labels to trigger workloads

Instead of always triggering your GPU workflows on every push or pull request you can use labels to trigger workflows. This is a great option if your project is public and anyone can make a pull request with any arbitrary code. You may want to have a mechanism for a trusted maintainer or collaborator to trigger the GPU workflow manually.

The scikit-learn project solved this by having a label that triggers the workflow.

```yaml
name: NVIDIA GPU workflow
on:
  pull_request:
    types:
      - labeled

jobs:
  tests:
    if: contains(github.event.pull_request.labels.*.name, 'GPU CI')
    runs-on:
      group: linux-nvidia-gpu
    steps: ...
```

The above config specifies a workflow should only be run when the `GPU CI` label is added to the pull request. They then have a second [label remover workflow](https://github.com/scikit-learn/scikit-learn/blob/9d39f57399d6f1f7d8e8d4351dbc3e9244b98d28/.github/workflows/cuda-label-remover.yml) which removed the label again, which allows a maintainer to add it again in the future to trigger the GPU CI workflow any number of times during the review of the pull request.

### Run nightly

Some projects might not need to run GPU tests for every pull request, but instead might prefer to run a nightly regression test to ensure that nothing that has been merged has broken GPU functionality.

You can configure a GitHub Actions workflow to run on a schedule and use [an action](https://github.com/marketplace/actions/failed-build-issue) to open an issue if the workflow fails.

```yaml
name: Nightly GPU Tests

on:
  schedule:
    - cron: "0 0 * * *" # Run every day at 00:00 UTC

jobs:
  tests:
    name: GPU Tests
    runs-on: linux-nvidia-gpu
    steps:
      - uses: actions/checkout@v4
      - name: Run tests
        run: |
          # Run tests here
      - name: Notify failed build
        uses: jayqi/failed-build-issue-action@v1
        if: failure() && github.event.pull_request == null
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
```

### Run only on certain codepaths

You may also want to only run your GPU CI tests when code at certain paths has been modified. To do this you can use the [`on.push.paths` filter](https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions#example-including-paths).

```yaml
name: GPU Tests
on:
  push:
    paths:
      - "src/gpu_submodule/**/*.py"

jobs:
  tests:
    name: GPU Tests
    runs-on: linux-nvidia-gpu
    steps: ...
```

## Further Reading

- [Blog from scikit-learn Developers on their experiences](https://betatim.github.io/posts/github-action-with-gpu/)
