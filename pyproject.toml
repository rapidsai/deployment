[tool.ruff]
fix = true
line-length = 120

[tool.ruff.lint]
select = [
    # pycodestyle
    "E",
    # pyflakes
    "F",
    # isort
    "I",
    # numpy
    "NPY",
    # pyupgrade
    "UP",
    # flake8-bugbear
    "B"
]

[tool.codespell]
# note: pre-commit passes explicit lists of files here, which this skip file list doesn't override -
# this is only to allow you to run codespell interactively
skip = "./.git,./build,./python/_skbuild/,.*egg-info.*,./.mypy_cache,./pyproject.toml,./benchmarks/utilities/cxxopts.hpp"
# ignore short words, and typename parameters like OffsetT
ignore-regex = "\\b(.{1,4}|[A-Z]\\w*T)\\b"
ignore-words-list = "thirdparty,couldn"
builtin = "clear"
quiet-level = 3

[tool.ruff.lint.per-file-ignores]
"source/examples/**/*.ipynb" = [
    # "module level import not at top of cell".
    # This is sometimes necessary, for example to ship a self-contained function
    # around with Dask.
    "E402",
]
"source/examples/rapids-ec2-mnmg/notebook.ipynb" = [
    # "undefined name cluster", because in this notebook we recommend, in a markdown
    # cell, creating a Dask cluster separately and then running the rest of the notebook's code
    "F821",
]
"source/examples/rapids-sagemaker-higgs/notebook.ipynb" = [
    # "Line too long", because of a 1-liner shell command starting with '!'
    "E501",
]
"source/examples/xgboost-dask-databricks/notebook.ipynb" = [
    # "undefined name spark" because Databricks magically makes a SparkSession
    # available with name 'spark'
    # ref: https://docs.databricks.com/en/migration/spark.html#remove-sparksession-creation-commands
    "F821",
]
